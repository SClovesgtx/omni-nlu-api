{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b740292",
   "metadata": {},
   "source": [
    "# Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ffd9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40f1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# setting working dir\n",
    "os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fd7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_db.elasticsearch import elastic_conection\n",
    "from elasticsearch_db.elasticsearch import get_nlp_model\n",
    "\n",
    "es = elastic_conection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb00a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace_id = \"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\"\n",
    "workspace, exist = get_nlp_model(es, workspace_id=workspace_id)\n",
    "exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8f0fd",
   "metadata": {},
   "source": [
    "# Data Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86856a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline.data_sourcing import get_data\n",
    "\n",
    "#get_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f4385a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "      <th>examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Como realizo a inativação de uma posição de mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Como realizo a reativação de uma posição em mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Em quanto tempo a inativação de uma posição é ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Gostaria de fazer a inativação de uma posição,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Realizei a inativação de uma posição e ela con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            intents                                           examples\n",
       "0  Inativar_Posição  Como realizo a inativação de uma posição de mi...\n",
       "1  Inativar_Posição  Como realizo a reativação de uma posição em mi...\n",
       "2  Inativar_Posição  Em quanto tempo a inativação de uma posição é ...\n",
       "3  Inativar_Posição  Gostaria de fazer a inativação de uma posição,...\n",
       "4  Inativar_Posição  Realizei a inativação de uma posição e ela con..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data(workspace=workspace, es=es)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd680f84",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659e631",
   "metadata": {},
   "source": [
    "### Create artificial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488f6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_pipeline.data_preprocessing import fill_missing_examples\n",
    "\n",
    "# fill_missing_examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe68237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = fill_missing_examples(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5680343",
   "metadata": {},
   "source": [
    "### Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe4ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline.data_preprocessing import clean_examples\n",
    "\n",
    "#clean_examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b695bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_examples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9887efd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "      <th>examples</th>\n",
       "      <th>cleaned_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Como realizo a inativação de uma posição de mi...</td>\n",
       "      <td>realiz inativ pos estrut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Como realizo a reativação de uma posição em mi...</td>\n",
       "      <td>realiz reativ pos estrut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Em quanto tempo a inativação de uma posição é ...</td>\n",
       "      <td>quant temp inativ pos efetiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Gostaria de fazer a inativação de uma posição,...</td>\n",
       "      <td>gost faz inativ pos fac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Realizei a inativação de uma posição e ela con...</td>\n",
       "      <td>realiz inativ pos continu vis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            intents                                           examples  \\\n",
       "0  Inativar_Posição  Como realizo a inativação de uma posição de mi...   \n",
       "1  Inativar_Posição  Como realizo a reativação de uma posição em mi...   \n",
       "2  Inativar_Posição  Em quanto tempo a inativação de uma posição é ...   \n",
       "3  Inativar_Posição  Gostaria de fazer a inativação de uma posição,...   \n",
       "4  Inativar_Posição  Realizei a inativação de uma posição e ela con...   \n",
       "\n",
       "                cleaned_examples  \n",
       "0       realiz inativ pos estrut  \n",
       "1       realiz reativ pos estrut  \n",
       "2   quant temp inativ pos efetiv  \n",
       "3        gost faz inativ pos fac  \n",
       "4  realiz inativ pos continu vis  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a86e9e",
   "metadata": {},
   "source": [
    "# Feature Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ada3cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "      <th>examples</th>\n",
       "      <th>cleaned_examples</th>\n",
       "      <th>13o</th>\n",
       "      <th>1a</th>\n",
       "      <th>2808sem</th>\n",
       "      <th>2k</th>\n",
       "      <th>2o</th>\n",
       "      <th>abaix</th>\n",
       "      <th>abat</th>\n",
       "      <th>...</th>\n",
       "      <th>vou</th>\n",
       "      <th>vr</th>\n",
       "      <th>vtnc</th>\n",
       "      <th>word</th>\n",
       "      <th>workflow</th>\n",
       "      <th>wwwpremiertravelc</th>\n",
       "      <th>xau</th>\n",
       "      <th>yar</th>\n",
       "      <th>yarin</th>\n",
       "      <th>zacarin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Como realizo a inativação de uma posição de mi...</td>\n",
       "      <td>realiz inativ pos estrut</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inativar_Posição</td>\n",
       "      <td>Como realizo a reativação de uma posição em mi...</td>\n",
       "      <td>realiz reativ pos estrut</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            intents                                           examples  \\\n",
       "0  Inativar_Posição  Como realizo a inativação de uma posição de mi...   \n",
       "1  Inativar_Posição  Como realizo a reativação de uma posição em mi...   \n",
       "\n",
       "           cleaned_examples  13o   1a  2808sem   2k   2o  abaix  abat  ...  \\\n",
       "0  realiz inativ pos estrut  0.0  0.0      0.0  0.0  0.0    0.0   0.0  ...   \n",
       "1  realiz reativ pos estrut  0.0  0.0      0.0  0.0  0.0    0.0   0.0  ...   \n",
       "\n",
       "   vou   vr  vtnc  word  workflow  wwwpremiertravelc  xau  yar  yarin  zacarin  \n",
       "0  0.0  0.0   0.0   0.0       0.0                0.0  0.0  0.0    0.0      0.0  \n",
       "1  0.0  0.0   0.0   0.0       0.0                0.0  0.0  0.0    0.0      0.0  \n",
       "\n",
       "[2 rows x 1177 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_pipeline.feature_extracting import encode_features\n",
    "\n",
    "df, x_transformer = encode_features(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f1a02",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0c43f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline.data_splitting import split\n",
    "\n",
    "# data_splitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a50e3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "913036af-6e60-4e29-9415-fa3626bfbf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 1174)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4920be40-0ea3-4a05-8b83-8adda8ab8f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ce755-3c51-42d1-af9e-31e8ea5bc782",
   "metadata": {},
   "source": [
    "# Feature Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff8eb70-f35c-493c-b209-167f88321551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def encode_features(train, test):\n",
    "    all_examples = train.examples.to_list() + test.examples.to_list()\n",
    "    transformer = TfidfVectorizer()\n",
    "    transformer.fit(all_examples)\n",
    "    \n",
    "    train_matrix = transformer.transform(train.examples.to_list()).toarray()\n",
    "    test_matrix = transformer.transform(test.examples.to_list()).toarray()\n",
    "    train[\"tfidf_vectors\"] = [row for row in train_matrix]\n",
    "    test[\"tfidf_vectors\"] = [row for row in test_matrix]\n",
    "    df1 = pd.DataFrame(x.toarray(), columns=v.get_feature_names())\n",
    "    \n",
    "    return train, test, transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94f76f-291e-420b-8040-5f354df35e48",
   "metadata": {},
   "source": [
    "# Scikit Learn Pipe Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6307a154-ab6c-4946-9244-8ba2f76e2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import make_column_transformer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8546f-d6b2-4976-9fd6-a9acec773079",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea0b6e-c3de-4dcd-9846-c410cad6bb15",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16c65571-09c5-4b27-85c7-9c823612bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_logreg(X, y, **hyper_parameters):\n",
    "    logreg = LogisticRegression(\n",
    "                    multi_class=\"multinomial\",\n",
    "                    n_jobs=-1,\n",
    "                    **hyper_parameters\n",
    "        )\n",
    "        \n",
    "    model = Pipeline(\n",
    "                steps= [\n",
    "                    ('text_features', TfidfVectorizer()),\n",
    "                    ('model', logreg)\n",
    "                ]\n",
    "            )\n",
    "#     regr = TransformedTargetRegressor(regressor=model,\n",
    "#                                    transformer=LabelEncoder())\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951944ff-ccde-4985-b7fa-c67928a91562",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "          \"C\": 5,\n",
    "          \"fit_intercept\": False,\n",
    "          \"random_state\": 1,\n",
    "          \"max_iter\": 1000\n",
    "        }\n",
    "\n",
    "logreg_clf = train_logreg(\n",
    "                    X=train.example_text, \n",
    "                    y=train.intent_name,\n",
    "                    **hyper_parameters\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92e265ea-a316-458c-8cdb-21dae32c7a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876122082585279"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg_clf.predict(test.example_text)\n",
    "np.sum((y_pred == test.intent_name)) / test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e08e29ac-edb3-4594-8cd8-d92e5ad18856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00250424, 0.00247818, 0.00235277, ..., 0.00357567, 0.00247282,\n",
       "        0.00251013],\n",
       "       [0.00306973, 0.00302721, 0.00284464, ..., 0.00470976, 0.00305399,\n",
       "        0.00308157],\n",
       "       [0.00146732, 0.00145828, 0.00136347, ..., 0.00218647, 0.00143466,\n",
       "        0.00187453],\n",
       "       ...,\n",
       "       [0.00292498, 0.00295398, 0.00293895, ..., 0.00369217, 0.00293383,\n",
       "        0.26013481],\n",
       "       [0.0025255 , 0.00254619, 0.0031367 , ..., 0.00250099, 0.00252309,\n",
       "        0.40970458],\n",
       "       [0.00226739, 0.00232928, 0.00226232, ..., 0.00290553, 0.00223531,\n",
       "        0.36142497]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_clf.predict_proba(test.example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f6ba2-6162-41da-8d3e-adb1e398ca36",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f686699-a81c-4287-b39b-3a09238df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def train_svm(X, y, **hyper_parameters):\n",
    "    poly_svm = svm.SVC(\n",
    "                    kernel=\"poly\", \n",
    "                    probability=True,\n",
    "                    **hyper_parameters\n",
    "              )\n",
    "        \n",
    "    model = Pipeline(\n",
    "                steps= [\n",
    "                    ('text_features', TfidfVectorizer()),\n",
    "                    ('model', poly_svm)\n",
    "                ]\n",
    "            )\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82cb3b88-8bdb-47bf-91a2-768dc820e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "          \"degree\": 1,\n",
    "          \"coef0\": 0,\n",
    "          \"random_state\": 42\n",
    "        }\n",
    "svm_clf = train_svm(\n",
    "                X=train.example_text, \n",
    "                y=train.intent_name,\n",
    "                **hyper_parameters\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a05ba871-61ed-4213-8087-129c64893d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6624775583482945"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(test.example_text)\n",
    "np.sum((y_pred == test.intent_name)) / test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0acc387-d1cf-4c30-8fff-41ecbb3b4ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ant',\n",
       " 'anteri',\n",
       " 'antig',\n",
       " 'aond',\n",
       " 'aparec',\n",
       " 'aparelh',\n",
       " 'apen',\n",
       " 'aplic',\n",
       " 'apos',\n",
       " 'app',\n",
       " 'apres',\n",
       " 'apresent',\n",
       " 'aprov',\n",
       " 'aproveit',\n",
       " 'apur',\n",
       " 'aqu',\n",
       " 'are',\n",
       " 'arquiv',\n",
       " 'asat',\n",
       " 'assalt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.named_steps[\"text_features\"].get_feature_names()[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c8f37b8-4fec-42ed-93ef-c6e52f2e3af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.intent_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a413bd9-73f7-4345-90ff-48e4a2eb026b",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2daaa93e-a1f5-405e-9ce7-e93aa9057c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin, BaseEstimator, clone\n",
    "import tensorflow as tf\n",
    "\n",
    "class MyTransformedTargetRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, regressor, transformer):\n",
    "        self.regressor = regressor\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def fit_transformer(self, y):\n",
    "        self.transformer_ = clone(self.transformer)\n",
    "        self.transformer_.fit(y)\n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "\n",
    "        # store the number of dimension of the target to predict an array of\n",
    "        # similar shape at predict\n",
    "        y = y.to_numpy()\n",
    "        self._training_dim = y.ndim\n",
    "\n",
    "        # transformers are designed to modify X which is 2d dimensional, we\n",
    "        # need to modify y accordingly.\n",
    "       \n",
    "        y_2d = y.reshape(-1, 1)\n",
    "        \n",
    "            \n",
    "        self.fit_transformer(y_2d)\n",
    "        y_trans = self.transformer_.transform(y_2d)\n",
    "\n",
    "        self.regressor_ = clone(self.regressor)\n",
    "\n",
    "        history = self.regressor_.fit(X, y_trans, **fit_params)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        pred = self.regressor_.predict(X)\n",
    "        if pred.ndim == 1:\n",
    "            pred_trans = self.transformer_.inverse_transform(\n",
    "                pred.reshape(-1, 1))\n",
    "        else:\n",
    "            pred_trans = self.transformer_.inverse_transform(pred)\n",
    "        if (self._training_dim == 1 and\n",
    "                pred_trans.ndim == 2 and pred_trans.shape[1] == 1):\n",
    "            pred_trans = pred_trans.squeeze(axis=1)\n",
    "\n",
    "        return pred_trans\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        pred = self.regressor_.predict_proba(X)\n",
    "        return pred\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {'poor_score': True, 'no_validation': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3fccfdd-b0e6-4687-864d-033886882b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "import numpy as np\n",
    "\n",
    "class MyTfidfVectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.transformer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        examples = X.to_list()\n",
    "        self.transformer_ = clone(self.transformer)\n",
    "        self.transformer_.fit(examples)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        examples = X.to_list()\n",
    "        features = self.transformer_.transform(examples)\n",
    "        tfidf_matrix = np.stack(features.toarray())\n",
    "        return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "381e5790-2f21-41ba-8ecf-b665fccd6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "all_data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "global learning_rate; learning_rate = 0.001\n",
    "global loss; loss = \"categorical_crossentropy\"\n",
    "global number_of_intent_classes \n",
    "number_of_intent_classes = all_data.intent_name.nunique()\n",
    "n_features = len(svm_clf.named_steps[\"text_features\"].get_feature_names())\n",
    "global input_shape; input_shape = (n_features,)\n",
    "\n",
    "# Keras Model\n",
    "def build_nn(**hyper_parameters):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "            Dense(\n",
    "                units=input_shape[0],\n",
    "                activation=\"relu\",\n",
    "                input_shape=input_shape,\n",
    "                name=\"input_layer\",\n",
    "            )\n",
    "    )\n",
    "    model.add(Dense(units=input_shape[0], activation=\"relu\", name=\"layer_2\"))\n",
    "    # Output\n",
    "    model.add(\n",
    "        Dense(units=number_of_intent_classes, activation=\"softmax\", name=\"output_layer\")\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_nn(X, y, **hyper_parameters):\n",
    "    nn = KerasClassifier(build_fn=build_nn,\n",
    "                          **hyper_parameters)\n",
    "    nn._estimator_type = \"classifier\"\n",
    "    model = Pipeline(\n",
    "                steps= [\n",
    "                    ('text_features', MyTfidfVectorizer()),\n",
    "                    ('model', nn)\n",
    "                ]\n",
    "            )\n",
    "    regres = MyTransformedTargetRegressor(\n",
    "                                regressor=model,\n",
    "                                transformer=OneHotEncoder(sparse=False)\n",
    "            )\n",
    "    regres.fit(X, y, validation_split=0.2);\n",
    "    return regres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa111636-bfaa-46be-8bfe-262e6f01bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected axis -1 of input shape to have value 1077 but received input with shape (None, 1258)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9835d6fa26bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintent_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mhyper_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m           )\n",
      "\u001b[0;32m<ipython-input-35-d653c446acee>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(X, y, **hyper_parameters)\u001b[0m\n\u001b[1;32m     54\u001b[0m                                 \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             )\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mregres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mregres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-021413ad32f6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected axis -1 of input shape to have value 1077 but received input with shape (None, 1258)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hyper_parameters = {\n",
    "  \"epochs\": 5,\n",
    "  \"verbose\":True,\n",
    "  \"batch_size\": 50,\n",
    "  \"validation_split\":0.33\n",
    "}\n",
    "\n",
    "all_data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "nn_clf = train_nn(\n",
    "                X=all_data.example_text, \n",
    "                y=all_data.intent_name,\n",
    "                **hyper_parameters\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66ea4644-eb3d-4aba-94c7-01df74ee2f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('text_features', MyTfidfVectorizer()),\n",
       "                ('model',\n",
       "                 <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f743b0b3278>)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae8ad7-5407-4690-8e9b-01a0e1e1e25f",
   "metadata": {},
   "source": [
    "# Train ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64537f-f0c0-4b73-938c-c15f4ea9e4a8",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "06bc94bb-b11c-49ca-ac02-137e06552945",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The estimator MyTransformedTargetRegressor should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-2debfd626f2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                       \u001b[0mvoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'soft'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                       \u001b[0mflatten_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                       n_jobs=-1)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-2debfd626f2c>\u001b[0m in \u001b[0;36mtrain_voting\u001b[0;34m(X_train, y_train, estimators, weights, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#                                 transformer=IndexLabelEncode(y=y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#             )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmeta_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         if (self.weights is not None and\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 raise ValueError(\n\u001b[1;32m    242\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[0;32m--> 243\u001b[0;31m                         \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m                     )\n\u001b[1;32m    245\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: The estimator MyTransformedTargetRegressor should be a classifier."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def train_voting(X_train, y_train, estimators, weights, **kwargs):\n",
    "    meta_model = VotingClassifier(\n",
    "                        estimators=estimators,\n",
    "                        weights=weights,\n",
    "                        **kwargs)\n",
    "#     model = TransformedTargetRegressor(\n",
    "#                                 regressor=meta_model,\n",
    "#                                 transformer=IndexLabelEncode(y=y)\n",
    "#             )\n",
    "    meta_model.fit(X_train, y_train)\n",
    "    return meta_model\n",
    "\n",
    "\n",
    "estimators = [('clf1', logreg_clf), \n",
    "              ('clf2', svm_clf),\n",
    "              ('clf3', nn_clf)]\n",
    "weights = [0.6929982046678635, 0.6427289048473968, 0.6894075274467468]\n",
    "voting = train_voting(train.example_text, train.intent_name, \n",
    "                      estimators, \n",
    "                      weights,\n",
    "                      voting='soft',\n",
    "                      flatten_transform=True,\n",
    "                      n_jobs=-1)\n",
    "y_pred = voting.predict(X_test)\n",
    "accuracy = np.sum((y_pred == y_test).all(1)) / y_test.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288f93e-dd95-477e-9713-f5b09d50faee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93b704b9-5e0c-4a2b-897f-d2866f947daa",
   "metadata": {},
   "source": [
    "# Prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84b4669-5305-4f92-8b14-7a955cd964c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# setting working dir\n",
    "os.chdir(\"../src\")\n",
    "\n",
    "from prefect import Flow, task, context\n",
    "\n",
    "from data_pipeline.data_sourcing import get_data\n",
    "from data_pipeline.data_preprocessing import fill_missing_examples, clean_examples\n",
    "from data_pipeline.feature_engineering import intents_to_onehot, create_corpus, encode_features\n",
    "from data_pipeline.data_splitting import data_splitting\n",
    "from elasticsearch_db.elasticsearch import elastic_conection\n",
    "from elasticsearch_db.elasticsearch import get_nlp_model\n",
    "\n",
    "es = elastic_conection()\n",
    "workspace_id = \"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\"\n",
    "workspace, exist = get_nlp_model(es, workspace_id=workspace_id)\n",
    "exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a30874-1902-4d1b-a530-0f23507a178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def sourcing(workspace, es):\n",
    "\n",
    "    return get_data(\n",
    "                workspace=workspace, \n",
    "                es=es\n",
    "            )\n",
    "\n",
    "@task\n",
    "def imputation(data):\n",
    "    \n",
    "    return fill_missing_examples(data)\n",
    "\n",
    "@task\n",
    "def cleansing(data):\n",
    "\n",
    "    return clean_examples(data)\n",
    "\n",
    "@task(nout=2)\n",
    "def splitting(data):\n",
    "\n",
    "    return data_splitting(data)\n",
    "\n",
    "@task(nout=4)\n",
    "def encoding(train, test):\n",
    "    all_intents = set([example[0] for example in train])\n",
    "    map_onehot, intent_dictionary = intents_to_onehot(\n",
    "                                        intents_name=all_intents\n",
    "                                    )\n",
    "    all_examples = [example[0] for example in train] + \\\n",
    "                   [example[0] for example in test]\n",
    "        \n",
    "    corpus = create_corpus(examples_text=all_examples)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = encode_features(\n",
    "                                            train=train, \n",
    "                                            test=test, \n",
    "                                            corpus=corpus, \n",
    "                                            map_onehot=map_onehot\n",
    "                                    )\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ea3fd3-6302-46e6-90a9-9fa2bdb27691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prefect flow\n",
    "with Flow(\"train_dataflow\") as flow:\n",
    "\n",
    "    data = sourcing(workspace=workspace, es=es)\n",
    "    data = imputation(data=data)\n",
    "    data = cleansing(data=data)\n",
    "    train, test = splitting(data=data)\n",
    "    X_train, y_train, X_test, y_test = encoding(train=train, \n",
    "                                                test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c659cdfd-f058-440a-a250-f7452b086456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-04-21 12:08:00+0000] INFO - prefect.FlowRunner | Beginning Flow run for 'train_dataflow'\n",
      "[2021-04-21 12:08:01+0000] INFO - prefect.TaskRunner | Task 'sourcing': Starting task run...\n",
      "[2021-04-21 12:08:01+0000] INFO - prefect.TaskRunner | Task 'sourcing': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:01+0000] INFO - prefect.TaskRunner | Task 'imputation': Starting task run...\n",
      "[2021-04-21 12:08:21+0000] INFO - prefect.TaskRunner | Task 'imputation': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:21+0000] INFO - prefect.TaskRunner | Task 'cleansing': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'cleansing': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting[1]': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting[0]': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding[2]': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding[2]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding[0]': Starting task run...\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[1]': Starting task run...\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[3]': Starting task run...\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[3]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"586pt\" height=\"566pt\"\n",
       " viewBox=\"0.00 0.00 586.29 566.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 562)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-562 582.2884,-562 582.2884,4 -4,4\"/>\n",
       "<!-- 139668601656320 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139668601656320</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-279\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting</text>\n",
       "</g>\n",
       "<!-- 139668601658056 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139668601658056</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"217.6442\" cy=\"-192\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"217.6442\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting[1]</text>\n",
       "</g>\n",
       "<!-- 139668601656320&#45;&gt;139668601658056 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139668601656320&#45;&gt;139668601658056</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M267.4082,-262.6028C260.654,-256.8222 253.4395,-250.0077 247.6442,-243 241.5559,-235.638 235.9319,-226.8943 231.2384,-218.7444\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.2545,-216.9658 226.3595,-209.9005 228.1253,-220.3472 234.2545,-216.9658\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.1442\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601658000 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139668601658000</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"360.6442\" cy=\"-192\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.6442\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting[0]</text>\n",
       "</g>\n",
       "<!-- 139668601656320&#45;&gt;139668601658000 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>139668601656320&#45;&gt;139668601658000</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M309.2235,-262.4352C315.8037,-256.6434 322.8718,-249.8647 328.6442,-243 334.9005,-235.5597 340.8344,-226.7946 345.8544,-218.6492\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.0017,-220.2042 351.1023,-209.8197 342.9843,-216.6277 349.0017,-220.2042\"/>\n",
       "<text text-anchor=\"middle\" x=\"380.1442\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601658560 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139668601658560</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"65.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[1]</text>\n",
       "</g>\n",
       "<!-- 139668601658840 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139668601658840</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"214.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"214.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[3]</text>\n",
       "</g>\n",
       "<!-- 139668601655368 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139668601655368</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-540\" rx=\"51.1914\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sourcing</text>\n",
       "</g>\n",
       "<!-- 139668601655760 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139668601655760</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-453\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">imputation</text>\n",
       "</g>\n",
       "<!-- 139668601655368&#45;&gt;139668601655760 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139668601655368&#45;&gt;139668601655760</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-521.9735C288.6442,-510.1918 288.6442,-494.5607 288.6442,-481.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-481.0033 288.6442,-471.0034 285.1443,-481.0034 292.1443,-481.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139668601657832 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139668601657832</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-105\" rx=\"53.0913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding</text>\n",
       "</g>\n",
       "<!-- 139668601658056&#45;&gt;139668601657832 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139668601658056&#45;&gt;139668601657832</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.0121,-174.3943C242.3093,-161.7765 256.3361,-144.5887 267.8535,-130.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"270.6866,-132.54 274.2976,-122.5796 265.2633,-128.1141 270.6866,-132.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"271.6442\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">test</text>\n",
       "</g>\n",
       "<!-- 139668601657832&#45;&gt;139668601658560 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>139668601657832&#45;&gt;139668601658560</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M244.4596,-94.7531C219.9458,-88.4809 189.1466,-79.6216 162.6442,-69 142.0407,-60.7426 120.0711,-49.4196 102.2594,-39.5401\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.7848,-36.3824 93.3533,-34.5292 100.3523,-42.4831 103.7848,-36.3824\"/>\n",
       "<text text-anchor=\"middle\" x=\"203.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601657832&#45;&gt;139668601658840 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139668601657832&#45;&gt;139668601658840</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M273.6692,-87.3943C262.9368,-74.7765 248.3174,-57.5887 236.3133,-43.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.742,-40.9291 229.5969,-35.5796 233.4099,-45.4645 238.742,-40.9291\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601659176 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139668601659176</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"363.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[2]</text>\n",
       "</g>\n",
       "<!-- 139668601657832&#45;&gt;139668601659176 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139668601657832&#45;&gt;139668601659176</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M317.452,-89.6791C326.0678,-84.054 334.983,-77.0594 341.6442,-69 347.2345,-62.2362 351.6303,-53.8368 354.9745,-45.8192\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.2862,-46.9563 358.5416,-36.3646 351.7369,-44.4853 358.2862,-46.9563\"/>\n",
       "<text text-anchor=\"middle\" x=\"392.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601657272 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139668601657272</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"512.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"512.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[0]</text>\n",
       "</g>\n",
       "<!-- 139668601657832&#45;&gt;139668601657272 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139668601657832&#45;&gt;139668601657272</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M337.3672,-97.6186C366.9293,-92.0609 404.941,-82.9613 436.6442,-69 452.9872,-61.8029 469.6277,-51.0963 483.1549,-41.3484\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"485.6043,-43.8899 491.5602,-35.1276 481.44,-38.2633 485.6043,-43.8899\"/>\n",
       "<text text-anchor=\"middle\" x=\"503.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601658000&#45;&gt;139668601657832 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139668601658000&#45;&gt;139668601657832</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M346.0739,-174.3943C335.6316,-161.7765 321.4073,-144.5887 309.7277,-130.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"312.2649,-128.052 303.1928,-122.5796 306.8721,-132.515 312.2649,-128.052\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.1442\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train</text>\n",
       "</g>\n",
       "<!-- 139668601655928 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>139668601655928</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-366\" rx=\"55.4913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cleansing</text>\n",
       "</g>\n",
       "<!-- 139668601655760&#45;&gt;139668601655928 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139668601655760&#45;&gt;139668601655928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-434.9735C288.6442,-423.1918 288.6442,-407.5607 288.6442,-394.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-394.0033 288.6442,-384.0034 285.1443,-394.0034 292.1443,-394.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139668601655928&#45;&gt;139668601656320 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139668601655928&#45;&gt;139668601656320</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-347.9735C288.6442,-336.1918 288.6442,-320.5607 288.6442,-307.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-307.0033 288.6442,-297.0034 285.1443,-307.0034 292.1443,-307.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f07215be908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run prefect flow\n",
    "flow.run()\n",
    "\n",
    "# Export flow as a PDF\n",
    "flow.visualize(filename=\"../src/data_pipeline/flow_diagrams/train_dataflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9623a-36cf-4c86-9048-fbeec2f5a173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
