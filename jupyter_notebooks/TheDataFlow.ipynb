{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b740292",
   "metadata": {},
   "source": [
    "# Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40f1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# setting working dir\n",
    "os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fd7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_db.elasticsearch import elastic_conection\n",
    "from elasticsearch_db.elasticsearch import get_nlp_model\n",
    "\n",
    "es = elastic_conection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb00a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace_id = \"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\"\n",
    "workspace, exist = get_nlp_model(es, workspace_id=workspace_id)\n",
    "exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8f0fd",
   "metadata": {},
   "source": [
    "# Data Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86856a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Get all the intents in the elasticsearch\n",
       "workspace's index.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "workspace: the workspace object\n",
       "es: the elasticsearch conection instance\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Intents\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_sourcing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_sourcing import get_data\n",
    "\n",
    "get_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f4385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "Intent(intent_name='Inativar_Posição', examples_text=['Como realizo a inativação de uma posição de minha estrutura?', 'Como realizo a reativação de uma posição em minha estrutura?', 'Em quanto tempo a inativação de uma posição é efetivada?', 'Gostaria de fazer a inativação de uma posição, como faço?', 'Realizei a inativação de uma posição e ela continua visível?'])\n"
     ]
    }
   ],
   "source": [
    "data = get_data(workspace=workspace, es=es)\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd680f84",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659e631",
   "metadata": {},
   "source": [
    "### Create artificial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488f6c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mfill_missing_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "We expect at least 8 examples for each intent,\n",
       "5 to train and 3 to test the ML models.\n",
       "\n",
       "This function identify intents with less then 8 examples\n",
       "and fill it up with artificial examples created from the \n",
       "exesting ones.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: list of namedtuple representing Intents\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "input = [\n",
       "    Intent(\n",
       "        intent_name='Inativar_Posição', \n",
       "        examples_text=['Como realizo a inativação de uma posição de minha estrutura?', \n",
       "                       'Como realizo a reativação de uma posição em minha estrutura?', \n",
       "                       'Em quanto tempo a inativação de uma posição é efetivada?', \n",
       "                       'Gostaria de fazer a inativação de uma posição, como faço?', \n",
       "                       'Realizei a inativação de uma posição e ela continua visível?']\n",
       "        )\n",
       "]\n",
       "\n",
       "output = [\n",
       "    Intent(\n",
       "        intent_name='Inativar_Posição', \n",
       "        examples_text=['Como realizo a inativação de uma posição de minha estrutura?', \n",
       "                       'Como realizo a reativação de uma posição em minha estrutura?', \n",
       "                       'Em quanto tempo a inativação de uma posição é efetivada?', \n",
       "                       'Gostaria de fazer a inativação de uma posição, como faço?', \n",
       "                       'Realizei a inativação de uma posição e ela continua visível?', \n",
       "                       'como realizar o inativação de umar posição de meu estruturar', \n",
       "                       'realizei o inativação de umar posição e ele continuar visível', \n",
       "                       'em quantum tempo o inativação de umar posição ser efetivada']\n",
       "    )\n",
       "]\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_preprocessing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_preprocessing import fill_missing_examples\n",
    "\n",
    "fill_missing_examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe68237",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fill_missing_examples(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5680343",
   "metadata": {},
   "source": [
    "### Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe4ef07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mclean_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Clean examples.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Examples.\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Please, see the TheDataFlow.ipynb notebook \n",
       "in the jupyter_notebook directory. Look for\n",
       "Data Preprocessing topic and Cleansing sub-topic.\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_preprocessing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_preprocessing import clean_examples\n",
    "\n",
    "clean_examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b695bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_examples(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9887efd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intent(intent_name='Inativar_Posição', examples_text=['realiz inativ pos estrut', 'realiz reativ pos estrut', 'quant temp inativ pos efetiv', 'gost faz inativ pos fac', 'realiz inativ pos continu vis', 'realiz inativ um pos estrutur', 'realiz inativ um pos continu vis', 'quantum temp inativ um pos efetiv'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f1a02",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c43f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mdata_splitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The split between train, valid and test sets occurs at the \n",
       "intent level. We want to assure that all intents \n",
       "are represented in boths sets.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "test_ratio: a float, between 0.0 and 1.0, that tells the\n",
       "percentage of examples to chose from a intent if it has eight \n",
       "or more examples.\n",
       "\n",
       "random_seed: the random seed.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Examples.\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Please, see the TheDataFlow.ipynb notebook \n",
       "in the jupyter_notebook directory. Look for\n",
       "Data Splitting topic.\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_splitting.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_splitting import data_splitting\n",
    "\n",
    "data_splitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a50e3d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096 557\n"
     ]
    }
   ],
   "source": [
    "train, test = data_splitting(data)\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0900564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3369630973986691"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test) / (len(train) + len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e950f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example(intent_name='Inativar_Posição', example_text='quant temp inativ pos efetiv'),\n",
       " Example(intent_name='Inativar_Posição', example_text='gost faz inativ pos fac'),\n",
       " Example(intent_name='Inativar_Posição', example_text='realiz inativ pos continu vis')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c7e4c7b-3207-431e-b16b-19dbfaa4a8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example(intent_name='Vizinho_Invadindo_Terreno', example_text='unidad send invad pod ajud'),\n",
       " Example(intent_name='Vizinho_Invadindo_Terreno', example_text='terren send invad vi unidad faz'),\n",
       " Example(intent_name='Vizinho_Invadindo_Terreno', example_text='est problem vi unidad pod fal')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f61bf-cd83-496c-91c8-a58757afe1e7",
   "metadata": {},
   "source": [
    "# Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973428b3-fc49-4b93-9c2b-e8fb49fa09e9",
   "metadata": {},
   "source": [
    "### Intents Onehot map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5636eb56-dada-4335-9189-f518fe8c2069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mintents_to_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/feature_engineering.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.feature_engineering import intents_to_onehot\n",
    "\n",
    "intents_to_onehot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76666c69-36f6-47bb-a808-86759d3ee21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mintents_to_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mintents_to_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0marray_intents_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintent_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mintent_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintents_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0monehot_intents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_intents_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmap_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mintent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot_intents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# use to identify the intent name \u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# in the prediction fase\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mintent_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mmap_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintent_dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/feature_engineering.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??intents_to_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "833f4fd1-6c36-41f4-817d-fa215e914a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_name = set([intent[0] for intent in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d9b3fad-9092-48d4-be14-949e5f862eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_onehot, intent_dictionary = intents_to_onehot(intents_name=intents_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a28523-c0e1-4edb-a1d7-841c0ca388a5",
   "metadata": {},
   "source": [
    "### TF-IDF corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4439ec8-488a-4fb3-b058-ffdc14dd4c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcreate_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/feature_engineering.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.feature_engineering import create_corpus\n",
    "\n",
    "create_corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13ad182f-e76c-4cde-9a7f-d16052b2b574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcreate_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mcreate_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/feature_engineering.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??create_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bd449a5-2d45-43c1-a24c-5c75b94b0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_text = [example[1] for example in train] + [example[1] for example in test]\n",
    "corpus = create_corpus(examples_text=examples_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c37e7-a6a8-4d52-8b85-af70bf2731de",
   "metadata": {},
   "source": [
    "### Examples as TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de05e04d-7b3b-4764-a9cf-2ec47a148168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mencode_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/feature_engineering.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.feature_engineering import encode_features\n",
    "\n",
    "encode_features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db95b603-a715-41af-8cb8-47263c376228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mencode_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mencode_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/feature_engineering.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??encode_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ca372d5-d307-4296-b5ee-4e4e8db675f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = encode_features(\n",
    "                                            train=train, \n",
    "                                            test=test, \n",
    "                                            corpus=corpus, \n",
    "                                            map_onehot=map_onehot\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85103650-eff0-424f-b9b5-5ea1ac44aab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1096, 1258)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c57bbacd-d818-42b4-b0ab-7cf8b2813084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1096, 206)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cd4342d-85ef-480b-9b43-c59007965724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 1258)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1315c4ac-57ba-4b1e-b591-155dab3d173e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 206)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae8ad7-5407-4690-8e9b-01a0e1e1e25f",
   "metadata": {},
   "source": [
    "# Train ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbaf6bbf-a7d0-4040-849d-1b1ba2408f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "hyper_parameters = {\n",
    "          \"C\": 5,\n",
    "          \"fit_intercept\": False,\n",
    "          \"random_state\": 1,\n",
    "          \"max_iter\": 1000\n",
    "        }\n",
    "def train_LogisticRegression(X, y, **hyper_parameters):\n",
    "    y = np.array([np.argmax(onehot) for onehot in y_train.tolist()])\n",
    "    model = LogisticRegression(**hyper_parameters)\n",
    "    model.fit(X, y);\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3da9219d-79be-46be-8b53-850e1a19ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_LogisticRegression(X=X_train,\n",
    "                                 y=y_train,\n",
    "                                 **hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3e5e78c-3868-4271-8c39-038affd4dec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6929982046678635"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test_int = np.array([np.argmax(onehot) for onehot in y_test.tolist()])\n",
    "accuracy = np.sum(y_pred == y_test_int) / y_test.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b704b9-5e0c-4a2b-897f-d2866f947daa",
   "metadata": {},
   "source": [
    "# Prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84b4669-5305-4f92-8b14-7a955cd964c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# setting working dir\n",
    "os.chdir(\"../src\")\n",
    "\n",
    "from prefect import Flow, task, context\n",
    "\n",
    "from data_pipeline.data_sourcing import get_data\n",
    "from data_pipeline.data_preprocessing import fill_missing_examples, clean_examples\n",
    "from data_pipeline.feature_engineering import intents_to_onehot, create_corpus, encode_features\n",
    "from data_pipeline.data_splitting import data_splitting\n",
    "from elasticsearch_db.elasticsearch import elastic_conection\n",
    "from elasticsearch_db.elasticsearch import get_nlp_model\n",
    "\n",
    "es = elastic_conection()\n",
    "workspace_id = \"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\"\n",
    "workspace, exist = get_nlp_model(es, workspace_id=workspace_id)\n",
    "exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a30874-1902-4d1b-a530-0f23507a178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def sourcing(workspace, es):\n",
    "\n",
    "    return get_data(\n",
    "                workspace=workspace, \n",
    "                es=es\n",
    "            )\n",
    "\n",
    "@task\n",
    "def imputation(data):\n",
    "    \n",
    "    return fill_missing_examples(data)\n",
    "\n",
    "@task\n",
    "def cleansing(data):\n",
    "\n",
    "    return clean_examples(data)\n",
    "\n",
    "@task(nout=2)\n",
    "def splitting(data):\n",
    "\n",
    "    return data_splitting(data)\n",
    "\n",
    "@task(nout=4)\n",
    "def encoding(train, test):\n",
    "    all_intents = set([example[0] for example in train])\n",
    "    map_onehot, intent_dictionary = intents_to_onehot(\n",
    "                                        intents_name=all_intents\n",
    "                                    )\n",
    "    all_examples = [example[0] for example in train] + \\\n",
    "                   [example[0] for example in test]\n",
    "        \n",
    "    corpus = create_corpus(examples_text=all_examples)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = encode_features(\n",
    "                                            train=train, \n",
    "                                            test=test, \n",
    "                                            corpus=corpus, \n",
    "                                            map_onehot=map_onehot\n",
    "                                    )\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ea3fd3-6302-46e6-90a9-9fa2bdb27691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prefect flow\n",
    "with Flow(\"train_dataflow\") as flow:\n",
    "\n",
    "    data = sourcing(workspace=workspace, es=es)\n",
    "    data = imputation(data=data)\n",
    "    data = cleansing(data=data)\n",
    "    train, test = splitting(data=data)\n",
    "    X_train, y_train, X_test, y_test = encoding(train=train, \n",
    "                                                test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c659cdfd-f058-440a-a250-f7452b086456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-04-13 16:44:41+0000] INFO - prefect.FlowRunner | Beginning Flow run for 'train_dataflow'\n",
      "[2021-04-13 16:44:41+0000] INFO - prefect.TaskRunner | Task 'sourcing': Starting task run...\n",
      "[2021-04-13 16:44:41+0000] INFO - prefect.TaskRunner | Task 'sourcing': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:44:41+0000] INFO - prefect.TaskRunner | Task 'imputation': Starting task run...\n",
      "[2021-04-13 16:45:05+0000] INFO - prefect.TaskRunner | Task 'imputation': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:05+0000] INFO - prefect.TaskRunner | Task 'cleansing': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'cleansing': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'splitting': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'splitting': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'splitting[0]': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'splitting[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'splitting[1]': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'splitting[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding[1]': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding[3]': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding[3]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding[2]': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding[2]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding[0]': Starting task run...\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.TaskRunner | Task 'encoding[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-13 16:45:06+0000] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"586pt\" height=\"566pt\"\n",
       " viewBox=\"0.00 0.00 586.29 566.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 562)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-562 582.2884,-562 582.2884,4 -4,4\"/>\n",
       "<!-- 139998504588512 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139998504588512</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-540\" rx=\"51.1914\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sourcing</text>\n",
       "</g>\n",
       "<!-- 139998504588736 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139998504588736</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-453\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">imputation</text>\n",
       "</g>\n",
       "<!-- 139998504588512&#45;&gt;139998504588736 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>139998504588512&#45;&gt;139998504588736</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-521.9735C288.6442,-510.1918 288.6442,-494.5607 288.6442,-481.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-481.0033 288.6442,-471.0034 285.1443,-481.0034 292.1443,-481.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139998504587616 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139998504587616</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-279\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting</text>\n",
       "</g>\n",
       "<!-- 139998504590696 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139998504590696</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"217.6442\" cy=\"-192\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"217.6442\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting[0]</text>\n",
       "</g>\n",
       "<!-- 139998504587616&#45;&gt;139998504590696 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>139998504587616&#45;&gt;139998504590696</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M267.4082,-262.6028C260.654,-256.8222 253.4395,-250.0077 247.6442,-243 241.5559,-235.638 235.9319,-226.8943 231.2384,-218.7444\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.2545,-216.9658 226.3595,-209.9005 228.1253,-220.3472 234.2545,-216.9658\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.1442\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139998504591032 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>139998504591032</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"360.6442\" cy=\"-192\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.6442\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting[1]</text>\n",
       "</g>\n",
       "<!-- 139998504587616&#45;&gt;139998504591032 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139998504587616&#45;&gt;139998504591032</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M309.2235,-262.4352C315.8037,-256.6434 322.8718,-249.8647 328.6442,-243 334.9005,-235.5597 340.8344,-226.7946 345.8544,-218.6492\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.0017,-220.2042 351.1023,-209.8197 342.9843,-216.6277 349.0017,-220.2042\"/>\n",
       "<text text-anchor=\"middle\" x=\"379.1442\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139998504587784 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139998504587784</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-366\" rx=\"55.4913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cleansing</text>\n",
       "</g>\n",
       "<!-- 139998504588736&#45;&gt;139998504587784 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139998504588736&#45;&gt;139998504587784</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-434.9735C288.6442,-423.1918 288.6442,-407.5607 288.6442,-394.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-394.0033 288.6442,-384.0034 285.1443,-394.0034 292.1443,-394.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139998504587784&#45;&gt;139998504587616 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139998504587784&#45;&gt;139998504587616</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-347.9735C288.6442,-336.1918 288.6442,-320.5607 288.6442,-307.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-307.0033 288.6442,-297.0034 285.1443,-307.0034 292.1443,-307.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139998504589800 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139998504589800</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-105\" rx=\"53.0913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding</text>\n",
       "</g>\n",
       "<!-- 139998504590696&#45;&gt;139998504589800 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139998504590696&#45;&gt;139998504589800</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.0121,-174.3943C242.3093,-161.7765 256.3361,-144.5887 267.8535,-130.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"270.6866,-132.54 274.2976,-122.5796 265.2633,-128.1141 270.6866,-132.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"275.1442\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train</text>\n",
       "</g>\n",
       "<!-- 139998504339720 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139998504339720</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"65.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[1]</text>\n",
       "</g>\n",
       "<!-- 139998504589800&#45;&gt;139998504339720 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139998504589800&#45;&gt;139998504339720</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M244.4596,-94.7531C219.9458,-88.4809 189.1466,-79.6216 162.6442,-69 142.0407,-60.7426 120.0711,-49.4196 102.2594,-39.5401\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.7848,-36.3824 93.3533,-34.5292 100.3523,-42.4831 103.7848,-36.3824\"/>\n",
       "<text text-anchor=\"middle\" x=\"203.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139998504011592 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139998504011592</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"214.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"214.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[3]</text>\n",
       "</g>\n",
       "<!-- 139998504589800&#45;&gt;139998504011592 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139998504589800&#45;&gt;139998504011592</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M273.6692,-87.3943C262.9368,-74.7765 248.3174,-57.5887 236.3133,-43.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.742,-40.9291 229.5969,-35.5796 233.4099,-45.4645 238.742,-40.9291\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139998504339160 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139998504339160</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"363.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[2]</text>\n",
       "</g>\n",
       "<!-- 139998504589800&#45;&gt;139998504339160 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139998504589800&#45;&gt;139998504339160</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M317.452,-89.6791C326.0678,-84.054 334.983,-77.0594 341.6442,-69 347.2345,-62.2362 351.6303,-53.8368 354.9745,-45.8192\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.2862,-46.9563 358.5416,-36.3646 351.7369,-44.4853 358.2862,-46.9563\"/>\n",
       "<text text-anchor=\"middle\" x=\"391.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139998501886776 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139998501886776</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"512.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"512.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[0]</text>\n",
       "</g>\n",
       "<!-- 139998504589800&#45;&gt;139998501886776 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139998504589800&#45;&gt;139998501886776</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M337.3437,-97.4402C366.6465,-91.8356 404.2326,-82.7491 435.6442,-69 452.3092,-61.7056 469.3263,-50.8599 483.1104,-41.0433\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"485.2308,-43.8288 491.243,-35.1051 481.1029,-38.1755 485.2308,-43.8288\"/>\n",
       "<text text-anchor=\"middle\" x=\"502.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139998504591032&#45;&gt;139998504589800 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139998504591032&#45;&gt;139998504589800</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M346.0739,-174.3943C335.6316,-161.7765 321.4073,-144.5887 309.7277,-130.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"312.2649,-128.052 303.1928,-122.5796 306.8721,-132.515 312.2649,-128.052\"/>\n",
       "<text text-anchor=\"middle\" x=\"342.6442\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">test</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f547453c6d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run prefect flow\n",
    "flow.run()\n",
    "\n",
    "# Export flow as a PDF\n",
    "flow.visualize(filename=\"../src/data_pipeline/flow_diagrams/train_dataflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc5fac-3325-4840-ac04-06bff8429f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
