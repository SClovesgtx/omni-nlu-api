{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b740292",
   "metadata": {},
   "source": [
    "# Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40f1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# setting working dir\n",
    "os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fd7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_db.elasticsearch import elastic_conection\n",
    "from elasticsearch_db.elasticsearch import get_nlp_model\n",
    "\n",
    "es = elastic_conection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb00a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace_id = \"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\"\n",
    "workspace, exist = get_nlp_model(es, workspace_id=workspace_id)\n",
    "exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8f0fd",
   "metadata": {},
   "source": [
    "# Data Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86856a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Get all the intents in the elasticsearch\n",
       "workspace's index.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "workspace: the workspace object\n",
       "es: the elasticsearch conection instance\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Intents\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_sourcing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_sourcing import get_data\n",
    "\n",
    "get_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f4385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "Intent(intent_name='Inativar_Posição', examples_text=['Como realizo a inativação de uma posição de minha estrutura?', 'Como realizo a reativação de uma posição em minha estrutura?', 'Em quanto tempo a inativação de uma posição é efetivada?', 'Gostaria de fazer a inativação de uma posição, como faço?', 'Realizei a inativação de uma posição e ela continua visível?'])\n"
     ]
    }
   ],
   "source": [
    "data = get_data(workspace=workspace, es=es)\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd680f84",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659e631",
   "metadata": {},
   "source": [
    "### Create artificial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488f6c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mfill_missing_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "We expect at least 8 examples for each intent,\n",
       "5 to train and 3 to test the ML models.\n",
       "\n",
       "This function identify intents with less then 8 examples\n",
       "and fill it up with artificial examples created from the \n",
       "exesting ones.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: list of namedtuple representing Intents\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "input = [\n",
       "    Intent(\n",
       "        intent_name='Inativar_Posição', \n",
       "        examples_text=['Como realizo a inativação de uma posição de minha estrutura?', \n",
       "                       'Como realizo a reativação de uma posição em minha estrutura?', \n",
       "                       'Em quanto tempo a inativação de uma posição é efetivada?', \n",
       "                       'Gostaria de fazer a inativação de uma posição, como faço?', \n",
       "                       'Realizei a inativação de uma posição e ela continua visível?']\n",
       "        )\n",
       "]\n",
       "\n",
       "output = [\n",
       "    Intent(\n",
       "        intent_name='Inativar_Posição', \n",
       "        examples_text=['Como realizo a inativação de uma posição de minha estrutura?', \n",
       "                       'Como realizo a reativação de uma posição em minha estrutura?', \n",
       "                       'Em quanto tempo a inativação de uma posição é efetivada?', \n",
       "                       'Gostaria de fazer a inativação de uma posição, como faço?', \n",
       "                       'Realizei a inativação de uma posição e ela continua visível?', \n",
       "                       'como realizar o inativação de umar posição de meu estruturar', \n",
       "                       'realizei o inativação de umar posição e ele continuar visível', \n",
       "                       'em quantum tempo o inativação de umar posição ser efetivada']\n",
       "    )\n",
       "]\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_preprocessing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_preprocessing import fill_missing_examples\n",
    "\n",
    "fill_missing_examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe68237",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fill_missing_examples(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5680343",
   "metadata": {},
   "source": [
    "### Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe4ef07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mclean_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Clean examples.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Examples.\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Please, see the TheDataFlow.ipynb notebook \n",
       "in the jupyter_notebook directory. Look for\n",
       "Data Preprocessing topic and Cleansing sub-topic.\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_preprocessing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_preprocessing import clean_examples\n",
    "\n",
    "clean_examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b695bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_examples(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9887efd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intent(intent_name='Inativar_Posição', examples_text=['realiz inativ pos estrut', 'realiz reativ pos estrut', 'quant temp inativ pos efetiv', 'gost faz inativ pos fac', 'realiz inativ pos continu vis', 'realiz inativ um pos estrutur', 'realiz inativ um pos continu vis', 'quantum temp inativ um pos efetiv'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f1a02",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c43f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mdata_splitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The split between train and test sets occurs at the \n",
       "intent level. We want to assure that all intents \n",
       "are represented in boths sets.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "test_ratio: a float, between 0.0 and 1.0, that tells the\n",
       "percentage of examples to chose from a intent if it has eight \n",
       "or more examples.\n",
       "\n",
       "random_seed: the random seed.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Examples.\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Please, see the TheDataFlow.ipynb notebook \n",
       "in the jupyter_notebook directory. Look for\n",
       "Data Splitting topic.\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_splitting.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_splitting import data_splitting\n",
    "\n",
    "data_splitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a50e3d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096 557\n"
     ]
    }
   ],
   "source": [
    "train, test = data_splitting(data)\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0900564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3369630973986691"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test) / (len(train) + len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e950f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example(intent_name='Inativar_Posição', example_text='quant temp inativ pos efetiv'),\n",
       " Example(intent_name='Inativar_Posição', example_text='gost faz inativ pos fac'),\n",
       " Example(intent_name='Inativar_Posição', example_text='realiz inativ pos continu vis')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c7e4c7b-3207-431e-b16b-19dbfaa4a8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Example(intent_name='Vizinho_Invadindo_Terreno', example_text='terren est invad pel vizinh unidad faz'),\n",
       " Example(intent_name='Vizinho_Invadindo_Terreno', example_text='unidad est invad pod ajud'),\n",
       " Example(intent_name='Vizinho_Invadindo_Terreno', example_text='vizinh unidad est invad um part imovel yar faz')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f61bf-cd83-496c-91c8-a58757afe1e7",
   "metadata": {},
   "source": [
    "# Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973428b3-fc49-4b93-9c2b-e8fb49fa09e9",
   "metadata": {},
   "source": [
    "### Intents Onehot map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12be607c-a3b4-4a0c-a342-9a82cc1b9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def intents_to_onehot(data):\n",
    "    intents_name = set([intent[0] for intent in data])\n",
    "    array_intents_name = np.asarray([[intent_name] for intent_name in intents_name])\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_intents = encoder.fit_transform(array_intents_name) \n",
    "    map_onehot = {\n",
    "        intent: onehot\n",
    "        for intent, onehot in zip(intents_name, onehot_intents)\n",
    "    }\n",
    "    # use for prediction\n",
    "    intent_dictionary = {\n",
    "        str(np.argmax(value)): key\n",
    "        for key, value in zip(map_onehot.keys(), map_onehot.values())\n",
    "    }\n",
    "    return map_onehot, intent_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f0363e3-a77c-438f-9699-4b02338d31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_onehot, intent_dictionary = intents_to_onehot(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a28523-c0e1-4edb-a1d7-841c0ca388a5",
   "metadata": {},
   "source": [
    "### Examples as TF-IDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8f8e6-aa6f-4d54-a0a8-a01f96fc3474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93b704b9-5e0c-4a2b-897f-d2866f947daa",
   "metadata": {},
   "source": [
    "# Prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84b4669-5305-4f92-8b14-7a955cd964c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# setting working dir\n",
    "os.chdir(\"../src\")\n",
    "\n",
    "from prefect import Flow, task, context\n",
    "\n",
    "from data_pipeline.data_sourcing import get_data\n",
    "from data_pipeline.data_preprocessing import fill_missing_examples, clean_examples\n",
    "from data_pipeline.data_splitting import data_splitting\n",
    "from elasticsearch_db.elasticsearch import elastic_conection\n",
    "from elasticsearch_db.elasticsearch import get_nlp_model\n",
    "\n",
    "es = elastic_conection()\n",
    "workspace_id = \"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\"\n",
    "workspace, exist = get_nlp_model(es, workspace_id=workspace_id)\n",
    "exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a30874-1902-4d1b-a530-0f23507a178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def sourcing(workspace, es):\n",
    "\n",
    "    return get_data(\n",
    "                workspace=workspace, \n",
    "                es=es\n",
    "            )\n",
    "\n",
    "@task\n",
    "def treat_missing_data(data):\n",
    "    \n",
    "    return fill_missing_examples(data)\n",
    "\n",
    "@task\n",
    "def cleansing(data):\n",
    "\n",
    "    return clean_examples(data)\n",
    "\n",
    "\n",
    "\n",
    "@task(nout=2)\n",
    "def splitting(data):\n",
    "\n",
    "    return data_splitting(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ea3fd3-6302-46e6-90a9-9fa2bdb27691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prefect flow\n",
    "with Flow(\"greenhouse\") as flow:\n",
    "\n",
    "    data = sourcing(workspace=workspace, es=es)\n",
    "    data = treat_missing_data(data=data)\n",
    "    data = cleansing(data=data)\n",
    "    train, test = splitting(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c659cdfd-f058-440a-a250-f7452b086456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-04-12 14:52:13+0000] INFO - prefect.FlowRunner | Beginning Flow run for 'greenhouse'\n",
      "[2021-04-12 14:52:13+0000] INFO - prefect.TaskRunner | Task 'sourcing': Starting task run...\n",
      "[2021-04-12 14:52:13+0000] INFO - prefect.TaskRunner | Task 'sourcing': Finished task run for task with final state: 'Success'\n",
      "[2021-04-12 14:52:13+0000] INFO - prefect.TaskRunner | Task 'treat_missing_data': Starting task run...\n",
      "[2021-04-12 14:52:40+0000] INFO - prefect.TaskRunner | Task 'treat_missing_data': Finished task run for task with final state: 'Success'\n",
      "[2021-04-12 14:52:40+0000] INFO - prefect.TaskRunner | Task 'cleansing': Starting task run...\n",
      "[2021-04-12 14:52:41+0000] INFO - prefect.TaskRunner | Task 'cleansing': Finished task run for task with final state: 'Success'\n",
      "[2021-04-12 14:52:41+0000] INFO - prefect.TaskRunner | Task 'splitting': Starting task run...\n",
      "[2021-04-12 14:52:41+0000] INFO - prefect.TaskRunner | Task 'splitting': Finished task run for task with final state: 'Success'\n",
      "[2021-04-12 14:52:41+0000] INFO - prefect.TaskRunner | Task 'splitting[1]': Starting task run...\n",
      "[2021-04-12 14:52:41+0000] INFO - prefect.TaskRunner | Task 'splitting[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-12 14:52:41+0000] INFO - prefect.TaskRunner | Task 'splitting[0]': Starting task run...\n",
      "[2021-04-12 14:52:41+0000] INFO - prefect.TaskRunner | Task 'splitting[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-12 14:52:41+0000] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"281pt\" height=\"392pt\"\n",
       " viewBox=\"0.00 0.00 281.39 392.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 388)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-388 277.3945,-388 277.3945,4 -4,4\"/>\n",
       "<!-- 139775956614784 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139775956614784</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"133.3945\" cy=\"-105\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.3945\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting</text>\n",
       "</g>\n",
       "<!-- 139775956668544 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139775956668544</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"62.3945\" cy=\"-18\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.3945\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting[1]</text>\n",
       "</g>\n",
       "<!-- 139775956614784&#45;&gt;139775956668544 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139775956614784&#45;&gt;139775956668544</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M118.0951,-87.5587C113.0387,-81.7084 107.4224,-75.1167 102.3945,-69 95.7124,-60.8709 88.5746,-51.8753 82.2056,-43.7311\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.8012,-41.3675 75.8981,-35.6242 79.2764,-45.666 84.8012,-41.3675\"/>\n",
       "<text text-anchor=\"middle\" x=\"142.8945\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139775956614952 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139775956614952</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"205.3945\" cy=\"-18\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"205.3945\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting[0]</text>\n",
       "</g>\n",
       "<!-- 139775956614784&#45;&gt;139775956614952 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139775956614784&#45;&gt;139775956614952</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M160.2946,-89.5915C168.5018,-83.92 177.0285,-76.9205 183.3945,-69 188.8917,-62.1604 193.2606,-53.739 196.6088,-45.7247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.9155,-46.8757 200.1938,-36.2846 193.3715,-44.3906 199.9155,-46.8757\"/>\n",
       "<text text-anchor=\"middle\" x=\"232.8945\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139775956614616 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139775956614616</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"133.3945\" cy=\"-192\" rx=\"55.4913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.3945\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cleansing</text>\n",
       "</g>\n",
       "<!-- 139775956614616&#45;&gt;139775956614784 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139775956614616&#45;&gt;139775956614784</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M133.3945,-173.9735C133.3945,-162.1918 133.3945,-146.5607 133.3945,-133.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.8946,-133.0033 133.3945,-123.0034 129.8946,-133.0034 136.8946,-133.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.3945\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139775956613720 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139775956613720</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"133.3945\" cy=\"-366\" rx=\"51.1914\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.3945\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sourcing</text>\n",
       "</g>\n",
       "<!-- 139775956614168 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139775956614168</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"133.3945\" cy=\"-279\" rx=\"100.1823\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.3945\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">treat_missing_data</text>\n",
       "</g>\n",
       "<!-- 139775956613720&#45;&gt;139775956614168 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139775956613720&#45;&gt;139775956614168</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M133.3945,-347.9735C133.3945,-336.1918 133.3945,-320.5607 133.3945,-307.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.8946,-307.0033 133.3945,-297.0034 129.8946,-307.0034 136.8946,-307.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.3945\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139775956614168&#45;&gt;139775956614616 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139775956614168&#45;&gt;139775956614616</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M133.3945,-260.9735C133.3945,-249.1918 133.3945,-233.5607 133.3945,-220.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.8946,-220.0033 133.3945,-210.0034 129.8946,-220.0034 136.8946,-220.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.3945\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f20a19eca90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run prefect flow\n",
    "flow.run()\n",
    "\n",
    "# Export flow as a PDF\n",
    "flow.visualize(filename=\"../src/data_pipeline/flow_diagram/data_flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc5fac-3325-4840-ac04-06bff8429f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
