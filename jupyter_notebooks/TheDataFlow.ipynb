{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b740292",
   "metadata": {},
   "source": [
    "# Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40f1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# setting working dir\n",
    "os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fd7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_db.elasticsearch import elastic_conection\n",
    "from elasticsearch_db.elasticsearch import get_nlp_model\n",
    "\n",
    "es = elastic_conection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb00a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace_id = \"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\"\n",
    "workspace, exist = get_nlp_model(es, workspace_id=workspace_id)\n",
    "exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8f0fd",
   "metadata": {},
   "source": [
    "# Data Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86856a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Get all the intents in the elasticsearch\n",
       "workspace's index.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "workspace: the workspace object\n",
       "es: the elasticsearch conection instance\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Intents\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_sourcing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_sourcing import get_data\n",
    "\n",
    "get_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f4385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "Intent(intent_name='Inativar_Posição', examples_text=['Como realizo a inativação de uma posição de minha estrutura?', 'Como realizo a reativação de uma posição em minha estrutura?', 'Em quanto tempo a inativação de uma posição é efetivada?', 'Gostaria de fazer a inativação de uma posição, como faço?', 'Realizei a inativação de uma posição e ela continua visível?'])\n"
     ]
    }
   ],
   "source": [
    "data = get_data(workspace=workspace, es=es)\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd680f84",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659e631",
   "metadata": {},
   "source": [
    "### Create artificial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488f6c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mfill_missing_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "We expect at least 8 examples for each intent,\n",
       "5 to train and 3 to test the ML models.\n",
       "\n",
       "This function identify intents with less then 8 examples\n",
       "and fill it up with artificial examples created from the \n",
       "exesting ones.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: list of namedtuple representing Intents\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "input = [\n",
       "    Intent(\n",
       "        intent_name='Inativar_Posição', \n",
       "        examples_text=['Como realizo a inativação de uma posição de minha estrutura?', \n",
       "                       'Como realizo a reativação de uma posição em minha estrutura?', \n",
       "                       'Em quanto tempo a inativação de uma posição é efetivada?', \n",
       "                       'Gostaria de fazer a inativação de uma posição, como faço?', \n",
       "                       'Realizei a inativação de uma posição e ela continua visível?']\n",
       "        )\n",
       "]\n",
       "\n",
       "output = [\n",
       "    Intent(\n",
       "        intent_name='Inativar_Posição', \n",
       "        examples_text=['Como realizo a inativação de uma posição de minha estrutura?', \n",
       "                       'Como realizo a reativação de uma posição em minha estrutura?', \n",
       "                       'Em quanto tempo a inativação de uma posição é efetivada?', \n",
       "                       'Gostaria de fazer a inativação de uma posição, como faço?', \n",
       "                       'Realizei a inativação de uma posição e ela continua visível?', \n",
       "                       'como realizar o inativação de umar posição de meu estruturar', \n",
       "                       'realizei o inativação de umar posição e ele continuar visível', \n",
       "                       'em quantum tempo o inativação de umar posição ser efetivada']\n",
       "    )\n",
       "]\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_preprocessing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_preprocessing import fill_missing_examples\n",
    "\n",
    "fill_missing_examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe68237",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fill_missing_examples(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5680343",
   "metadata": {},
   "source": [
    "### Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe4ef07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mclean_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Clean examples.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Examples.\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Please, see the TheDataFlow.ipynb notebook \n",
       "in the jupyter_notebook directory. Look for\n",
       "Data Preprocessing topic and Cleansing sub-topic.\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_preprocessing.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_preprocessing import clean_examples\n",
    "\n",
    "clean_examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b695bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_examples(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9887efd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intent(intent_name='Inativar_Posição', examples_text=['realiz inativ pos estrut', 'realiz reativ pos estrut', 'quant temp inativ pos efetiv', 'gost faz inativ pos fac', 'realiz inativ pos continu vis', 'realiz inativ um pos estrutur', 'realiz inativ um pos continu vis', 'quantum temp inativ um pos efetiv'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f1a02",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c43f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mdata_splitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The split between train, valid and test sets occurs at the \n",
       "intent level. We want to assure that all intents \n",
       "are represented in boths sets.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data: list of namedtuple representing Intents\n",
       "\n",
       "test_ratio: a float, between 0.0 and 1.0, that tells the\n",
       "percentage of examples to chose from a intent if it has eight \n",
       "or more examples.\n",
       "\n",
       "random_seed: the random seed.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "list: a list of namedtuple Examples.\n",
       "    \n",
       "Examples\n",
       "--------\n",
       "\n",
       "Please, see the TheDataFlow.ipynb notebook \n",
       "in the jupyter_notebook directory. Look for\n",
       "Data Splitting topic.\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/omni_nlu_api/src/data_pipeline/data_splitting.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_pipeline.data_splitting import data_splitting\n",
    "\n",
    "data_splitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a50e3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_splitting(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "913036af-6e60-4e29-9415-fa3626bfbf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_name</th>\n",
       "      <th>example_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>Vizinho_Invadindo_Terreno</td>\n",
       "      <td>est problem vi unidad poss fal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>Vizinho_Invadindo_Terreno</td>\n",
       "      <td>vi unidad invad part imovel yar faz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>Vizinho_Invadindo_Terreno</td>\n",
       "      <td>terren est invad pel vizinh unidad faz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>Vizinho_Invadindo_Terreno</td>\n",
       "      <td>unidad est invad pod ajud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Vizinho_Invadindo_Terreno</td>\n",
       "      <td>vizinh unidad est invad um part imovel yar faz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    intent_name  \\\n",
       "1091  Vizinho_Invadindo_Terreno   \n",
       "1092  Vizinho_Invadindo_Terreno   \n",
       "1093  Vizinho_Invadindo_Terreno   \n",
       "1094  Vizinho_Invadindo_Terreno   \n",
       "1095  Vizinho_Invadindo_Terreno   \n",
       "\n",
       "                                        example_text  \n",
       "1091                  est problem vi unidad poss fal  \n",
       "1092             vi unidad invad part imovel yar faz  \n",
       "1093          terren est invad pel vizinh unidad faz  \n",
       "1094                       unidad est invad pod ajud  \n",
       "1095  vizinh unidad est invad um part imovel yar faz  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4920be40-0ea3-4a05-8b83-8adda8ab8f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_name</th>\n",
       "      <th>example_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Visao_Geral_Previdencia_Privada</td>\n",
       "      <td>pod fal sobr previd priv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Visao_Geral_Previdencia_Privada</td>\n",
       "      <td>com funcion plan previd priv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>Vizinho_Invadindo_Terreno</td>\n",
       "      <td>unidad send invad pod ajud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Vizinho_Invadindo_Terreno</td>\n",
       "      <td>terren send invad vi unidad faz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>Vizinho_Invadindo_Terreno</td>\n",
       "      <td>est problem vi unidad pod fal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         intent_name                     example_text\n",
       "552  Visao_Geral_Previdencia_Privada         pod fal sobr previd priv\n",
       "553  Visao_Geral_Previdencia_Privada     com funcion plan previd priv\n",
       "554        Vizinho_Invadindo_Terreno       unidad send invad pod ajud\n",
       "555        Vizinho_Invadindo_Terreno  terren send invad vi unidad faz\n",
       "556        Vizinho_Invadindo_Terreno    est problem vi unidad pod fal"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94f76f-291e-420b-8040-5f354df35e48",
   "metadata": {},
   "source": [
    "# Scikit Learn Pipe Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6307a154-ab6c-4946-9244-8ba2f76e2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import make_column_transformer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bef15b9d-0783-4b26-8adb-4077a3388827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111, 111, 111, ..., 205, 205, 205])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer = LabelBinarizer()\n",
    "transformer = LabelEncoder()\n",
    "y_train = np.ravel(transformer.fit_transform(train.intent_name))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89ca9140-9b68-428c-b69c-94fbf40b0688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Inativar_Posição', 'Fazer_Contrato', 'Vizinho_Invadindo_Terreno',\n",
       "       'Abono', 'Abrir_Chamado_Salario'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.inverse_transform([111, 100, 205, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15717ce9-22c0-4981-b3d1-763ded1f96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "          \"C\": 5,\n",
    "          \"fit_intercept\": False,\n",
    "          \"random_state\": 1,\n",
    "          \"max_iter\": 1000\n",
    "        }\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "                    multi_class=\"multinomial\",\n",
    "                    n_jobs=-1,\n",
    "                    **hyper_parameters\n",
    "        )\n",
    "        \n",
    "\n",
    "model = Pipeline(\n",
    "            steps= [\n",
    "                ('text_features', TfidfVectorizer()),\n",
    "                ('model', logreg)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48f2b79e-a428-4f53-a21c-ad103a5cd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = text_features.fit_transform(train.example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "394e3ddf-a6a4-4c61-a314-3da21ce95347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6688293897882939"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, train.example_text, y_train, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "628fe606-7f15-4d9f-a4b9-ec5614811432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('text_features', TfidfVectorizer()),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=5, fit_intercept=False, max_iter=1000,\n",
       "                                    multi_class='multinomial', n_jobs=-1,\n",
       "                                    random_state=1))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train.example_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3feebb2-1813-443c-a9af-e4644fb7cb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b458b76d-5ba3-4b8c-8a63-6d32822bd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = text_features.fit_transform(train.example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad67114c-0645-4b07-b3f6-380b33508e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quant temp inativ pos efetiv']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train.example_text[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb6e8827-97bc-4980-988b-f31a8166909e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00161367, 0.00162917, 0.00153952, 0.00161252, 0.00160862,\n",
       "        0.00162839, 0.00161768, 0.00776304, 0.00161973, 0.00159184,\n",
       "        0.00161182, 0.00155349, 0.00161711, 0.00163906, 0.00157892,\n",
       "        0.0016162 , 0.00162226, 0.00163381, 0.00162664, 0.00155312,\n",
       "        0.00152386, 0.00160225, 0.00161829, 0.00160845, 0.00161433,\n",
       "        0.00160944, 0.00323867, 0.00160048, 0.00162622, 0.00161679,\n",
       "        0.00845913, 0.00544037, 0.00164158, 0.00163864, 0.00162907,\n",
       "        0.00158999, 0.00159081, 0.00160694, 0.00155991, 0.00160983,\n",
       "        0.00164227, 0.00163695, 0.00161367, 0.00160783, 0.00160283,\n",
       "        0.00163553, 0.00163   , 0.00163305, 0.00162953, 0.00162846,\n",
       "        0.00148005, 0.00162406, 0.00161066, 0.00159372, 0.00163411,\n",
       "        0.00159805, 0.00162368, 0.00163461, 0.00162646, 0.00163889,\n",
       "        0.00157984, 0.00157542, 0.00162571, 0.00162885, 0.00156692,\n",
       "        0.01178298, 0.00164173, 0.00163307, 0.00156552, 0.001621  ,\n",
       "        0.0016254 , 0.00163418, 0.00162608, 0.0016264 , 0.00161666,\n",
       "        0.00163968, 0.00156771, 0.00163779, 0.00197171, 0.00160896,\n",
       "        0.00159165, 0.00162197, 0.00157697, 0.00163526, 0.00163586,\n",
       "        0.00250395, 0.00161134, 0.00162863, 0.0016379 , 0.00159966,\n",
       "        0.00162357, 0.00163313, 0.00162752, 0.00163823, 0.00163425,\n",
       "        0.0016031 , 0.00162971, 0.001619  , 0.00162469, 0.00163377,\n",
       "        0.00158186, 0.00163854, 0.00162232, 0.00157705, 0.00164209,\n",
       "        0.00164216, 0.00163267, 0.00163303, 0.00239045, 0.00159951,\n",
       "        0.00163437, 0.60483004, 0.00152752, 0.00159346, 0.00162754,\n",
       "        0.00161825, 0.00161731, 0.00164267, 0.00157505, 0.00251781,\n",
       "        0.00162206, 0.00162215, 0.00156084, 0.00250389, 0.00162738,\n",
       "        0.00162822, 0.0016283 , 0.0016387 , 0.00153852, 0.00162529,\n",
       "        0.00162919, 0.00163183, 0.00161338, 0.00163603, 0.00163363,\n",
       "        0.00163438, 0.00163495, 0.00159795, 0.00160744, 0.00161472,\n",
       "        0.00163828, 0.0037731 , 0.00465955, 0.00164109, 0.00154497,\n",
       "        0.00161151, 0.00157106, 0.00162181, 0.00162091, 0.00162361,\n",
       "        0.00163493, 0.00163423, 0.00162134, 0.00162212, 0.00161463,\n",
       "        0.00163111, 0.00163214, 0.00159878, 0.00159642, 0.00300848,\n",
       "        0.00160067, 0.00163459, 0.00158745, 0.00155621, 0.0038734 ,\n",
       "        0.00162598, 0.00164513, 0.00161347, 0.00163796, 0.00163102,\n",
       "        0.00159739, 0.00162329, 0.00162462, 0.00162354, 0.00162863,\n",
       "        0.00163077, 0.00162462, 0.01834526, 0.00163853, 0.00163682,\n",
       "        0.0025491 , 0.00161266, 0.00150174, 0.001594  , 0.00161136,\n",
       "        0.00164414, 0.00160134, 0.00163482, 0.00322372, 0.00163455,\n",
       "        0.00164141, 0.00241317, 0.00162607, 0.00259172, 0.00159328,\n",
       "        0.00161189, 0.00237901, 0.00212272, 0.00161305, 0.00230011,\n",
       "        0.00163566, 0.00162358, 0.0016256 , 0.00160262, 0.00161963,\n",
       "        0.00162933]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([train.example_text[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8546f-d6b2-4976-9fd6-a9acec773079",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea0b6e-c3de-4dcd-9846-c410cad6bb15",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c65571-09c5-4b27-85c7-9c823612bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_logreg(X, y, **hyper_parameters):\n",
    "    logreg = LogisticRegression(\n",
    "                    multi_class=\"multinomial\",\n",
    "                    n_jobs=-1,\n",
    "                    **hyper_parameters\n",
    "        )\n",
    "        \n",
    "    model = Pipeline(\n",
    "                steps= [\n",
    "                    ('text_features', TfidfVectorizer()),\n",
    "                    ('model', logreg)\n",
    "                ]\n",
    "            )\n",
    "#     regr = TransformedTargetRegressor(regressor=model,\n",
    "#                                    transformer=LabelEncoder())\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "951944ff-ccde-4985-b7fa-c67928a91562",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "          \"C\": 5,\n",
    "          \"fit_intercept\": False,\n",
    "          \"random_state\": 1,\n",
    "          \"max_iter\": 1000\n",
    "        }\n",
    "\n",
    "logreg_clf = train_logreg(\n",
    "                    X=train.example_text, \n",
    "                    y=train.intent_name,\n",
    "                    **hyper_parameters\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92e265ea-a316-458c-8cdb-21dae32c7a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876122082585279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg_clf.predict(test.example_text)\n",
    "np.sum((y_pred == test.intent_name)) / test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e08e29ac-edb3-4594-8cd8-d92e5ad18856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00250424, 0.00247818, 0.00235277, ..., 0.00357567, 0.00247282,\n",
       "        0.00251013],\n",
       "       [0.00306973, 0.00302721, 0.00284464, ..., 0.00470976, 0.00305399,\n",
       "        0.00308157],\n",
       "       [0.00146732, 0.00145828, 0.00136347, ..., 0.00218647, 0.00143466,\n",
       "        0.00187453],\n",
       "       ...,\n",
       "       [0.00292498, 0.00295398, 0.00293895, ..., 0.00369217, 0.00293383,\n",
       "        0.26013481],\n",
       "       [0.0025255 , 0.00254619, 0.0031367 , ..., 0.00250099, 0.00252309,\n",
       "        0.40970458],\n",
       "       [0.00226739, 0.00232928, 0.00226232, ..., 0.00290553, 0.00223531,\n",
       "        0.36142497]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_clf.predict_proba(test.example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f6ba2-6162-41da-8d3e-adb1e398ca36",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f686699-a81c-4287-b39b-3a09238df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def train_svm(X, y, **hyper_parameters):\n",
    "    poly_svm = svm.SVC(\n",
    "                    kernel=\"poly\", \n",
    "                    probability=True,\n",
    "                    **hyper_parameters\n",
    "              )\n",
    "        \n",
    "    model = Pipeline(\n",
    "                steps= [\n",
    "                    ('text_features', TfidfVectorizer()),\n",
    "                    ('model', poly_svm)\n",
    "                ]\n",
    "            )\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82cb3b88-8bdb-47bf-91a2-768dc820e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "          \"degree\": 1,\n",
    "          \"coef0\": 0,\n",
    "          \"random_state\": 42\n",
    "        }\n",
    "svm_clf = train_svm(\n",
    "                X=train.example_text, \n",
    "                y=train.intent_name,\n",
    "                **hyper_parameters\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a05ba871-61ed-4213-8087-129c64893d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6624775583482945"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(test.example_text)\n",
    "np.sum((y_pred == test.intent_name)) / test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0acc387-d1cf-4c30-8fff-41ecbb3b4ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ant',\n",
       " 'anteri',\n",
       " 'antig',\n",
       " 'aond',\n",
       " 'aparec',\n",
       " 'aparelh',\n",
       " 'apen',\n",
       " 'aplic',\n",
       " 'apos',\n",
       " 'app',\n",
       " 'apres',\n",
       " 'apresent',\n",
       " 'aprov',\n",
       " 'aproveit',\n",
       " 'apur',\n",
       " 'aqu',\n",
       " 'are',\n",
       " 'arquiv',\n",
       " 'asat',\n",
       " 'assalt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.named_steps[\"text_features\"].get_feature_names()[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c8f37b8-4fec-42ed-93ef-c6e52f2e3af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.intent_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a413bd9-73f7-4345-90ff-48e4a2eb026b",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2daaa93e-a1f5-405e-9ce7-e93aa9057c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin, clone\n",
    "import tensorflow as tf\n",
    "\n",
    "class MyTransformedTargetRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, regressor, transformer):\n",
    "        self.regressor = regressor\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def fit_transformer(self, y):\n",
    "        self.transformer_ = clone(self.transformer)\n",
    "        self.transformer_.fit(y)\n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "\n",
    "        # store the number of dimension of the target to predict an array of\n",
    "        # similar shape at predict\n",
    "        y = y.to_numpy()\n",
    "        self._training_dim = y.ndim\n",
    "\n",
    "        # transformers are designed to modify X which is 2d dimensional, we\n",
    "        # need to modify y accordingly.\n",
    "       \n",
    "        y_2d = y.reshape(-1, 1)\n",
    "        \n",
    "            \n",
    "        self.fit_transformer(y_2d)\n",
    "        y_trans = self.transformer_.transform(y_2d)\n",
    "\n",
    "        self.regressor_ = clone(self.regressor)\n",
    "\n",
    "        history = self.regressor_.fit(X, y_trans, **fit_params)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        pred = self.regressor_.predict(X)\n",
    "        if pred.ndim == 1:\n",
    "            pred_trans = self.transformer_.inverse_transform(\n",
    "                pred.reshape(-1, 1))\n",
    "        else:\n",
    "            pred_trans = self.transformer_.inverse_transform(pred)\n",
    "        if (self._training_dim == 1 and\n",
    "                pred_trans.ndim == 2 and pred_trans.shape[1] == 1):\n",
    "            pred_trans = pred_trans.squeeze(axis=1)\n",
    "\n",
    "        return pred_trans\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        pred = self.regressor_.predict_proba(X)\n",
    "        return pred\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {'poor_score': True, 'no_validation': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f3fccfdd-b0e6-4687-864d-033886882b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "import numpy as np\n",
    "\n",
    "class MyTfidfVectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.transformer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        examples = X.to_list()\n",
    "        self.transformer_ = clone(self.transformer)\n",
    "        self.transformer_.fit(examples)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        examples = X.to_list()\n",
    "        features = self.transformer_.transform(examples)\n",
    "        tfidf_matrix = np.stack(features.toarray())\n",
    "        return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "381e5790-2f21-41ba-8ecf-b665fccd6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "global learning_rate; learning_rate = 0.001\n",
    "global loss; loss = \"categorical_crossentropy\"\n",
    "global number_of_intent_classes \n",
    "number_of_intent_classes = train.intent_name.nunique()\n",
    "n_features = len(svm_clf.named_steps[\"text_features\"].get_feature_names())\n",
    "global input_shape; input_shape = (n_features,)\n",
    "\n",
    "# Keras Model\n",
    "def build_nn(**hyper_parameters):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "            Dense(\n",
    "                units=input_shape[0],\n",
    "                activation=\"relu\",\n",
    "                input_shape=input_shape,\n",
    "                name=\"input_layer\",\n",
    "            )\n",
    "    )\n",
    "    model.add(Dense(units=input_shape[0], activation=\"relu\", name=\"layer_2\"))\n",
    "    # Output\n",
    "    model.add(\n",
    "        Dense(units=number_of_intent_classes, activation=\"softmax\", name=\"output_layer\")\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_nn(X, y, **hyper_parameters):\n",
    "    nn = KerasClassifier(build_fn=build_nn,\n",
    "                          **hyper_parameters)\n",
    "    nn._estimator_type = \"classifier\"\n",
    "    model = Pipeline(\n",
    "                steps= [\n",
    "                    ('text_features', MyTfidfVectorizer()),\n",
    "                    ('model', nn)\n",
    "                ]\n",
    "            )\n",
    "    regres = MyTransformedTargetRegressor(\n",
    "                                regressor=model,\n",
    "                                transformer=OneHotEncoder(sparse=False)\n",
    "            )\n",
    "    history = regres.fit(X, y);\n",
    "    return regres, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fa111636-bfaa-46be-8bfe-262e6f01bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 5.3109 - accuracy: 0.0356\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 4.9610 - accuracy: 0.0811\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 4.0544 - accuracy: 0.3121\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 2.4065 - accuracy: 0.7610\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 1.0167 - accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters = {\n",
    "  \"epochs\": 5,\n",
    "  \"verbose\":True,\n",
    "  \"batch_size\": 50\n",
    "}\n",
    "\n",
    "nn_clf, history = train_nn(\n",
    "                X=train.example_text, \n",
    "                y=train.intent_name,\n",
    "                **hyper_parameters\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae8ad7-5407-4690-8e9b-01a0e1e1e25f",
   "metadata": {},
   "source": [
    "# Train ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64537f-f0c0-4b73-938c-c15f4ea9e4a8",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "06bc94bb-b11c-49ca-ac02-137e06552945",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The estimator MyTransformedTargetRegressor should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-2debfd626f2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                       \u001b[0mvoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'soft'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                       \u001b[0mflatten_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                       n_jobs=-1)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-2debfd626f2c>\u001b[0m in \u001b[0;36mtrain_voting\u001b[0;34m(X_train, y_train, estimators, weights, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#                                 transformer=IndexLabelEncode(y=y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#             )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmeta_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         if (self.weights is not None and\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 raise ValueError(\n\u001b[1;32m    242\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[0;32m--> 243\u001b[0;31m                         \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m                     )\n\u001b[1;32m    245\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: The estimator MyTransformedTargetRegressor should be a classifier."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def train_voting(X_train, y_train, estimators, weights, **kwargs):\n",
    "    meta_model = VotingClassifier(\n",
    "                        estimators=estimators,\n",
    "                        weights=weights,\n",
    "                        **kwargs)\n",
    "#     model = TransformedTargetRegressor(\n",
    "#                                 regressor=meta_model,\n",
    "#                                 transformer=IndexLabelEncode(y=y)\n",
    "#             )\n",
    "    meta_model.fit(X_train, y_train)\n",
    "    return meta_model\n",
    "\n",
    "\n",
    "estimators = [('clf1', logreg_clf), \n",
    "              ('clf2', svm_clf),\n",
    "              ('clf3', nn_clf)]\n",
    "weights = [0.6929982046678635, 0.6427289048473968, 0.6894075274467468]\n",
    "voting = train_voting(train.example_text, train.intent_name, \n",
    "                      estimators, \n",
    "                      weights,\n",
    "                      voting='soft',\n",
    "                      flatten_transform=True,\n",
    "                      n_jobs=-1)\n",
    "y_pred = voting.predict(X_test)\n",
    "accuracy = np.sum((y_pred == y_test).all(1)) / y_test.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288f93e-dd95-477e-9713-f5b09d50faee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93b704b9-5e0c-4a2b-897f-d2866f947daa",
   "metadata": {},
   "source": [
    "# Prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84b4669-5305-4f92-8b14-7a955cd964c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# setting working dir\n",
    "os.chdir(\"../src\")\n",
    "\n",
    "from prefect import Flow, task, context\n",
    "\n",
    "from data_pipeline.data_sourcing import get_data\n",
    "from data_pipeline.data_preprocessing import fill_missing_examples, clean_examples\n",
    "from data_pipeline.feature_engineering import intents_to_onehot, create_corpus, encode_features\n",
    "from data_pipeline.data_splitting import data_splitting\n",
    "from elasticsearch_db.elasticsearch import elastic_conection\n",
    "from elasticsearch_db.elasticsearch import get_nlp_model\n",
    "\n",
    "es = elastic_conection()\n",
    "workspace_id = \"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\"\n",
    "workspace, exist = get_nlp_model(es, workspace_id=workspace_id)\n",
    "exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a30874-1902-4d1b-a530-0f23507a178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def sourcing(workspace, es):\n",
    "\n",
    "    return get_data(\n",
    "                workspace=workspace, \n",
    "                es=es\n",
    "            )\n",
    "\n",
    "@task\n",
    "def imputation(data):\n",
    "    \n",
    "    return fill_missing_examples(data)\n",
    "\n",
    "@task\n",
    "def cleansing(data):\n",
    "\n",
    "    return clean_examples(data)\n",
    "\n",
    "@task(nout=2)\n",
    "def splitting(data):\n",
    "\n",
    "    return data_splitting(data)\n",
    "\n",
    "@task(nout=4)\n",
    "def encoding(train, test):\n",
    "    all_intents = set([example[0] for example in train])\n",
    "    map_onehot, intent_dictionary = intents_to_onehot(\n",
    "                                        intents_name=all_intents\n",
    "                                    )\n",
    "    all_examples = [example[0] for example in train] + \\\n",
    "                   [example[0] for example in test]\n",
    "        \n",
    "    corpus = create_corpus(examples_text=all_examples)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = encode_features(\n",
    "                                            train=train, \n",
    "                                            test=test, \n",
    "                                            corpus=corpus, \n",
    "                                            map_onehot=map_onehot\n",
    "                                    )\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ea3fd3-6302-46e6-90a9-9fa2bdb27691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prefect flow\n",
    "with Flow(\"train_dataflow\") as flow:\n",
    "\n",
    "    data = sourcing(workspace=workspace, es=es)\n",
    "    data = imputation(data=data)\n",
    "    data = cleansing(data=data)\n",
    "    train, test = splitting(data=data)\n",
    "    X_train, y_train, X_test, y_test = encoding(train=train, \n",
    "                                                test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c659cdfd-f058-440a-a250-f7452b086456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-04-21 12:08:00+0000] INFO - prefect.FlowRunner | Beginning Flow run for 'train_dataflow'\n",
      "[2021-04-21 12:08:01+0000] INFO - prefect.TaskRunner | Task 'sourcing': Starting task run...\n",
      "[2021-04-21 12:08:01+0000] INFO - prefect.TaskRunner | Task 'sourcing': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:01+0000] INFO - prefect.TaskRunner | Task 'imputation': Starting task run...\n",
      "[2021-04-21 12:08:21+0000] INFO - prefect.TaskRunner | Task 'imputation': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:21+0000] INFO - prefect.TaskRunner | Task 'cleansing': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'cleansing': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting[1]': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting[0]': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'splitting[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding[2]': Starting task run...\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding[2]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:22+0000] INFO - prefect.TaskRunner | Task 'encoding[0]': Starting task run...\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[1]': Starting task run...\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[3]': Starting task run...\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.TaskRunner | Task 'encoding[3]': Finished task run for task with final state: 'Success'\n",
      "[2021-04-21 12:08:23+0000] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"586pt\" height=\"566pt\"\n",
       " viewBox=\"0.00 0.00 586.29 566.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 562)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-562 582.2884,-562 582.2884,4 -4,4\"/>\n",
       "<!-- 139668601656320 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139668601656320</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-279\" rx=\"50.0912\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting</text>\n",
       "</g>\n",
       "<!-- 139668601658056 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139668601658056</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"217.6442\" cy=\"-192\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"217.6442\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting[1]</text>\n",
       "</g>\n",
       "<!-- 139668601656320&#45;&gt;139668601658056 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139668601656320&#45;&gt;139668601658056</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M267.4082,-262.6028C260.654,-256.8222 253.4395,-250.0077 247.6442,-243 241.5559,-235.638 235.9319,-226.8943 231.2384,-218.7444\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.2545,-216.9658 226.3595,-209.9005 228.1253,-220.3472 234.2545,-216.9658\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.1442\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601658000 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139668601658000</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"360.6442\" cy=\"-192\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.6442\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">splitting[0]</text>\n",
       "</g>\n",
       "<!-- 139668601656320&#45;&gt;139668601658000 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>139668601656320&#45;&gt;139668601658000</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M309.2235,-262.4352C315.8037,-256.6434 322.8718,-249.8647 328.6442,-243 334.9005,-235.5597 340.8344,-226.7946 345.8544,-218.6492\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.0017,-220.2042 351.1023,-209.8197 342.9843,-216.6277 349.0017,-220.2042\"/>\n",
       "<text text-anchor=\"middle\" x=\"380.1442\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601658560 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139668601658560</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"65.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[1]</text>\n",
       "</g>\n",
       "<!-- 139668601658840 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139668601658840</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"214.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"214.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[3]</text>\n",
       "</g>\n",
       "<!-- 139668601655368 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139668601655368</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-540\" rx=\"51.1914\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-536.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sourcing</text>\n",
       "</g>\n",
       "<!-- 139668601655760 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139668601655760</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-453\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">imputation</text>\n",
       "</g>\n",
       "<!-- 139668601655368&#45;&gt;139668601655760 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139668601655368&#45;&gt;139668601655760</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-521.9735C288.6442,-510.1918 288.6442,-494.5607 288.6442,-481.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-481.0033 288.6442,-471.0034 285.1443,-481.0034 292.1443,-481.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139668601657832 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139668601657832</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-105\" rx=\"53.0913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding</text>\n",
       "</g>\n",
       "<!-- 139668601658056&#45;&gt;139668601657832 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139668601658056&#45;&gt;139668601657832</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.0121,-174.3943C242.3093,-161.7765 256.3361,-144.5887 267.8535,-130.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"270.6866,-132.54 274.2976,-122.5796 265.2633,-128.1141 270.6866,-132.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"271.6442\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">test</text>\n",
       "</g>\n",
       "<!-- 139668601657832&#45;&gt;139668601658560 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>139668601657832&#45;&gt;139668601658560</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M244.4596,-94.7531C219.9458,-88.4809 189.1466,-79.6216 162.6442,-69 142.0407,-60.7426 120.0711,-49.4196 102.2594,-39.5401\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.7848,-36.3824 93.3533,-34.5292 100.3523,-42.4831 103.7848,-36.3824\"/>\n",
       "<text text-anchor=\"middle\" x=\"203.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601657832&#45;&gt;139668601658840 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139668601657832&#45;&gt;139668601658840</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M273.6692,-87.3943C262.9368,-74.7765 248.3174,-57.5887 236.3133,-43.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.742,-40.9291 229.5969,-35.5796 233.4099,-45.4645 238.742,-40.9291\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601659176 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139668601659176</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"363.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[2]</text>\n",
       "</g>\n",
       "<!-- 139668601657832&#45;&gt;139668601659176 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139668601657832&#45;&gt;139668601659176</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M317.452,-89.6791C326.0678,-84.054 334.983,-77.0594 341.6442,-69 347.2345,-62.2362 351.6303,-53.8368 354.9745,-45.8192\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.2862,-46.9563 358.5416,-36.3646 351.7369,-44.4853 358.2862,-46.9563\"/>\n",
       "<text text-anchor=\"middle\" x=\"392.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601657272 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139668601657272</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"512.6442\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"512.6442\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">encoding[0]</text>\n",
       "</g>\n",
       "<!-- 139668601657832&#45;&gt;139668601657272 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139668601657832&#45;&gt;139668601657272</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M337.3672,-97.6186C366.9293,-92.0609 404.941,-82.9613 436.6442,-69 452.9872,-61.8029 469.6277,-51.0963 483.1549,-41.3484\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"485.6043,-43.8899 491.5602,-35.1276 481.44,-38.2633 485.6043,-43.8899\"/>\n",
       "<text text-anchor=\"middle\" x=\"503.1442\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">task_result</text>\n",
       "</g>\n",
       "<!-- 139668601658000&#45;&gt;139668601657832 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139668601658000&#45;&gt;139668601657832</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M346.0739,-174.3943C335.6316,-161.7765 321.4073,-144.5887 309.7277,-130.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"312.2649,-128.052 303.1928,-122.5796 306.8721,-132.515 312.2649,-128.052\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.1442\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train</text>\n",
       "</g>\n",
       "<!-- 139668601655928 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>139668601655928</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.6442\" cy=\"-366\" rx=\"55.4913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.6442\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cleansing</text>\n",
       "</g>\n",
       "<!-- 139668601655760&#45;&gt;139668601655928 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139668601655760&#45;&gt;139668601655928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-434.9735C288.6442,-423.1918 288.6442,-407.5607 288.6442,-394.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-394.0033 288.6442,-384.0034 285.1443,-394.0034 292.1443,-394.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- 139668601655928&#45;&gt;139668601656320 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139668601655928&#45;&gt;139668601656320</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.6442,-347.9735C288.6442,-336.1918 288.6442,-320.5607 288.6442,-307.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"292.1443,-307.0033 288.6442,-297.0034 285.1443,-307.0034 292.1443,-307.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.6442\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f07215be908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run prefect flow\n",
    "flow.run()\n",
    "\n",
    "# Export flow as a PDF\n",
    "flow.visualize(filename=\"../src/data_pipeline/flow_diagrams/train_dataflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9623a-36cf-4c86-9048-fbeec2f5a173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
