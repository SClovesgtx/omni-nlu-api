{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlp_model-dc1e7b3d-9137-4a20-a99c-d0d2029ef170-03012021112419'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elastic_db.elasticsearch import elastic_conection, NLPmodelIndex\n",
    "\n",
    "es = elastic_conection()\n",
    "index = NLPmodelIndex(es=es, workspace_id=\"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\")\n",
    "index.index_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"data/train_data.csv\", sep=\"|\")\n",
    "df_test = pd.read_csv(\"data/test_data.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Como visualizo o meu holerite?</td>\n",
       "      <td>Solicitar_Holerite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qual a essencia do CoE?</td>\n",
       "      <td>Foco_Cliente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Onde encontro informações sobre o processo par...</td>\n",
       "      <td>Alterar_EnquadramentoMerito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             example  \\\n",
       "0                     Como visualizo o meu holerite?   \n",
       "1                            Qual a essencia do CoE?   \n",
       "2  Onde encontro informações sobre o processo par...   \n",
       "\n",
       "                        intent  \n",
       "0           Solicitar_Holerite  \n",
       "1                 Foco_Cliente  \n",
       "2  Alterar_EnquadramentoMerito  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quais os assuntos você trata</td>\n",
       "      <td>Bot_Capabilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preciso trocar uma peça do meu carro, como dev...</td>\n",
       "      <td>Veiculo_Problema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Como modificar a senha do cartão Alelo VR, VA?</td>\n",
       "      <td>Esquecer_Senha_Vale_RefeicaoAlimentacao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             example  \\\n",
       "0                       quais os assuntos você trata   \n",
       "1  preciso trocar uma peça do meu carro, como dev...   \n",
       "2     Como modificar a senha do cartão Alelo VR, VA?   \n",
       "\n",
       "                                    intent  \n",
       "0                         Bot_Capabilities  \n",
       "1                         Veiculo_Problema  \n",
       "2  Esquecer_Senha_Vale_RefeicaoAlimentacao  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elastic to prepare text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 120 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['qua assunt voc trat']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import spacy\n",
    "\n",
    "start_time = time.time()\n",
    "query = {\n",
    "  \"tokenizer\" : \"classic\",\n",
    "  \"filter\" : [\n",
    "              \"lowercase\",\n",
    "              \"asciifolding\",\n",
    "              {\"type\": \"stop\", \"stopwords\": \"_portuguese_\"},\n",
    "              {\"type\": \"stemmer\", \"language\": \"brazilian\"}],\n",
    "  \"text\" : \"\"\n",
    "}\n",
    "\n",
    "train_examples_text_without_stopwords = []\n",
    "for train_example in df_train.example:\n",
    "    query[\"text\"] = train_example\n",
    "    result = es.indices.analyze(index=index.index_name, body=query)\n",
    "    new_text = \" \".join([token[\"token\"] for token in result[\"tokens\"]])\n",
    "    train_examples_text_without_stopwords.append(new_text)\n",
    "    \n",
    "test_examples_text_without_stopwords = []\n",
    "for test_example in df_test.example:\n",
    "    query[\"text\"] = test_example\n",
    "    result = es.indices.analyze(index=index.index_name, body=query)\n",
    "    new_text = \" \".join([token[\"token\"] for token in result[\"tokens\"]])\n",
    "    test_examples_text_without_stopwords.append(new_text)\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % round(time.time() - start_time))\n",
    "test_examples_text_without_stopwords[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Enconding the intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def intent_to_onehot(intents_names):\n",
    "    data = asarray([ [intent_name]  for intent_name in intents_names])\n",
    "    # define one hot encoding\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    # transform data\n",
    "    intents_names_as_onehot = encoder.fit_transform(data)\n",
    "    return intents_names_as_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_name = df_train.intent.tolist() + df_test.intent.tolist()\n",
    "set_intents_name = set(intent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_intents_name = set(intents_name)\n",
    "intents_name_as_onehot = intent_to_onehot(set_intents_name)\n",
    "dic_onehot_intents = {intent: onehot for intent, onehot in zip(set_intents_name, intents_name_as_onehot)}\n",
    "dic_onehot_intents[\"General_Negative_Feedback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "intent_dictionary = {str(np.argmax(value)):key for key, value in zip(dic_onehot_intents.keys(),\n",
    "                                            dic_onehot_intents.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/yarin_intents.json\", 'w') as f:\n",
    "    json.dump(intent_dictionary, f)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Hash Encoding on Examples\n",
    "\n",
    "\"*The class FeatureHasher is a high-speed, low-memory vectorizer that uses a technique known as feature hashing, or the “hashing trick”. Instead of building a hash table of the features encountered in training, as the vectorizers do, instances of FeatureHasher apply a hash function to the features to determine their column index in sample matrices directly. The result is increased speed and reduced memory usage, at the expense of inspectability; the hasher does not remember what the input features looked like and has no inverse_transform method.*\" [6.2.2. Feature hashing](https://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 20)\n",
      "[[ 0.         -0.43643578 -0.21821789 ... -0.21821789  0.43643578\n",
      "   0.        ]\n",
      " [-0.37796447 -0.37796447 -0.37796447 ...  0.          0.37796447\n",
      "   0.        ]\n",
      " [ 0.         -0.57735027  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ... -0.57735027  0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ... -0.70710678  0.\n",
      "   0.        ]\n",
      " [ 0.         -0.57735027  0.57735027 ... -0.57735027  0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# create the transform\n",
    "vectorizer = HashingVectorizer(n_features=20)\n",
    "# encode document\n",
    "vector = vectorizer.transform(examples_text_without_stopwords)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "encoded_examples = vector.toarray()\n",
    "print(encoded_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625 625\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "X = encoded_examples\n",
    "for intent in  intents_name:\n",
    "    y.append(dic_onehot_intents[intent])\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.stack(y)\n",
    "\n",
    "# salvando dados\n",
    "with open('data/X_hash_all_intents.npy', 'wb') as f:\n",
    "    np.save(f, X)\n",
    "    f.close()\n",
    "    \n",
    "with open('data/y_hash_all_intents.npy', 'wb') as f:\n",
    "    np.save(f, y)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": ".myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
