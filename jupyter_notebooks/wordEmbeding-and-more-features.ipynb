{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlp_model-dc1e7b3d-9137-4a20-a99c-d0d2029ef170-03012021112419'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elastic_db.elasticsearch import elastic_conection, NLPmodelIndex\n",
    "\n",
    "es = elastic_conection()\n",
    "index = NLPmodelIndex(es=es, workspace_id=\"dc1e7b3d-9137-4a20-a99c-d0d2029ef170\")\n",
    "index.index_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"data/intents_dictionary.json\", 'r') as f:\n",
    "      intents_dictionary = json.load(f)\n",
    "\n",
    "df_train = pd.read_csv(\"data/train_data.csv\", sep=\"|\")\n",
    "df_test = pd.read_csv(\"data/test_data.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Como visualizo o meu holerite?</td>\n",
       "      <td>Solicitar_Holerite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qual a essencia do CoE?</td>\n",
       "      <td>Foco_Cliente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Onde encontro informações sobre o processo par...</td>\n",
       "      <td>Alterar_EnquadramentoMerito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O Valor depositado do Cartão Alelo veio no Ref...</td>\n",
       "      <td>Valor_Depositado_Vale_RefeicaoAlimentacao_Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bom dia</td>\n",
       "      <td>General_Greetings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             example  \\\n",
       "0                     Como visualizo o meu holerite?   \n",
       "1                            Qual a essencia do CoE?   \n",
       "2  Onde encontro informações sobre o processo par...   \n",
       "3  O Valor depositado do Cartão Alelo veio no Ref...   \n",
       "4                                            Bom dia   \n",
       "\n",
       "                                             intent  \n",
       "0                                Solicitar_Holerite  \n",
       "1                                      Foco_Cliente  \n",
       "2                       Alterar_EnquadramentoMerito  \n",
       "3  Valor_Depositado_Vale_RefeicaoAlimentacao_Errado  \n",
       "4                                 General_Greetings  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quais os assuntos você trata</td>\n",
       "      <td>Bot_Capabilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preciso trocar uma peça do meu carro, como dev...</td>\n",
       "      <td>Veiculo_Problema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Como modificar a senha do cartão Alelo VR, VA?</td>\n",
       "      <td>Esquecer_Senha_Vale_RefeicaoAlimentacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estou com o contra-cheque, mas o pagamento ain...</td>\n",
       "      <td>Contracheque_Recebido_Sem_Constar_Conta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o pont fechou e o sistema está bloqueado, como...</td>\n",
       "      <td>Solicitar_Ponto_Pos_FechamentoReembolso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             example  \\\n",
       "0                       quais os assuntos você trata   \n",
       "1  preciso trocar uma peça do meu carro, como dev...   \n",
       "2     Como modificar a senha do cartão Alelo VR, VA?   \n",
       "3  Estou com o contra-cheque, mas o pagamento ain...   \n",
       "4  o pont fechou e o sistema está bloqueado, como...   \n",
       "\n",
       "                                    intent  \n",
       "0                         Bot_Capabilities  \n",
       "1                         Veiculo_Problema  \n",
       "2  Esquecer_Senha_Vale_RefeicaoAlimentacao  \n",
       "3  Contracheque_Recebido_Sem_Constar_Conta  \n",
       "4  Solicitar_Ponto_Pos_FechamentoReembolso  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "def keep_token(token):\n",
    "    return (token.is_alpha and \n",
    "            not (token.is_space or token.is_punct or \n",
    "                 token.is_stop or token.like_num))\n",
    "\n",
    "def to_lemas(doc):\n",
    "    sentence_lemmas = [token.lemma_ for token in doc if keep_token(token)]\n",
    "    return sentence_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modificar', 'o', 'senha', 'cartão', 'Alelo', 'VR', 'VA']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Como modificar a senha do cartão Alelo VR, VA?\")\n",
    "to_lemas(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = [to_lemas(nlp(example)) for example in df_train.example]\n",
    "test_stard_index = len(train_examples)\n",
    "test_examples = [to_lemas(nlp(example)) for example in df_test.example]\n",
    "all_examples = train_examples + test_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Encoding\n",
    "\n",
    "\n",
    "[UD Portuguese Bosque](https://universaldependencies.org/treebanks/pt_bosque/index.html)\n",
    "\n",
    "[Creating TF-IDF Weighted Word Embeddings](http://dsgeek.com/2018/02/19/tfidf_vectors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.matutils import sparse2full\n",
    "\n",
    "docs_dict = Dictionary(all_examples)\n",
    "#docs_dict.filter_extremes(no_below=20, no_above=0.2)\n",
    "docs_dict.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "docs_corpus = [docs_dict.doc2bow(doc) for doc in all_examples]\n",
    "model_tfidf = TfidfModel(docs_corpus, id2word=docs_dict)\n",
    "docs_tfidf  = model_tfidf[docs_corpus]\n",
    "docs_vecs   = np.vstack([sparse2full(c, len(docs_dict)) for c in docs_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 940)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "# use spaCy to get the 300 dimensional Glove embedding vector for each TF-IDF term\n",
    "tfidf_emb_vecs = np.vstack([nlp(docs_dict[i]).vector for i in range(len(docs_dict))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(940, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_emb_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a TF-IDF weighted we do matrix multiplication\n",
    "docs_emb = np.dot(docs_vecs, tfidf_emb_vecs) \n",
    "docs_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390 235\n"
     ]
    }
   ],
   "source": [
    "X_train  = docs_emb[:test_stard_index]\n",
    "X_test = docs_emb[test_stard_index:]\n",
    "print(X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Enconding the intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def intent_to_onehot(intents_names):\n",
    "    data = asarray([ [intent_name]  for intent_name in intents_names])\n",
    "    # define one hot encoding\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    # transform data\n",
    "    intents_names_as_onehot = encoder.fit_transform(data)\n",
    "    return intents_names_as_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_name = df_train.intent.tolist() + df_test.intent.tolist()\n",
    "set_intents_name = set(intents_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_intents_name = set(intents_name)\n",
    "intents_name_as_onehot = intent_to_onehot(set_intents_name)\n",
    "dic_onehot_intents = {intent: onehot for intent, onehot in zip(set_intents_name, intents_name_as_onehot)}\n",
    "dic_onehot_intents[\"General_Negative_Feedback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "intent_dictionary = {str(np.argmax(value)):key for key, value in zip(dic_onehot_intents.keys(),\n",
    "                                            dic_onehot_intents.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/yarin_intents.json\", 'w') as f:\n",
    "    json.dump(intent_dictionary, f)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390 235\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_train = [dic_onehot_intents[intent] for intent in df_train.intent]\n",
    "y_test = [dic_onehot_intents[intent] for intent in df_test.intent]\n",
    "\n",
    "y_train = np.stack(y_train)\n",
    "y_test = np.stack(y_test)\n",
    "print(y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando dados\n",
    "with open('data/X_train_embedding.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "    f.close()\n",
    "    \n",
    "with open('data/y_train_embedding.npy', 'wb') as f:\n",
    "    np.save(f, y_train)\n",
    "    f.close()\n",
    "    \n",
    "with open('data/X_test_embedding.npy', 'wb') as f:\n",
    "    np.save(f, X_test)\n",
    "    f.close()\n",
    "    \n",
    "with open('data/y_test_embedding.npy', 'wb') as f:\n",
    "    np.save(f, y_test)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": ".myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
