{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlp_model-dc1e7b3d-9137-4a20-a99c-d0d2029ef170-cedae-02022021092147'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elastic_db.elasticsearch import elastic_conection, NLPmodelIndex\n",
    "\n",
    "es = elastic_conection()\n",
    "index = NLPmodelIndex(es=es, workspace_id=\"dc1e7b3d-9137-4a20-a99c-d0d2029ef170-cedae\")\n",
    "index.index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dc1e7b3d-9137-4a20-a99c-d0d2029ef170-cedae'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.workspace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"data/train_data_cedae.csv\", sep=\",\")\n",
    "df_test = pd.read_csv(\"data/test_data_cedae.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A água está barrenta</td>\n",
       "      <td>Reportar_QualidadeDeAgua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero meu extrato de pagamento dos últimos meses</td>\n",
       "      <td>Consultar_ContasPagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contaminação da agua</td>\n",
       "      <td>Reportar_QualidadeDeAgua</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            example                    intent\n",
       "0                              A água está barrenta  Reportar_QualidadeDeAgua\n",
       "1  quero meu extrato de pagamento dos últimos meses     Consultar_ContasPagas\n",
       "2                              Contaminação da agua  Reportar_QualidadeDeAgua"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quero ir numa agência da CEDAE</td>\n",
       "      <td>Localizar_AgenciasCEDAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boa Noite</td>\n",
       "      <td>General_Greetings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quero um relatório dos meus pagamentos</td>\n",
       "      <td>Consultar_ContasPagas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  example                   intent\n",
       "0          quero ir numa agência da CEDAE  Localizar_AgenciasCEDAE\n",
       "1                               Boa Noite        General_Greetings\n",
       "2  quero um relatório dos meus pagamentos    Consultar_ContasPagas"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = df_train.example.tolist()\n",
    "stard_idx_test = len(train_examples)\n",
    "all_examples = train_examples + df_test.example.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic to prepare text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agu barrent',\n",
       " 'quer extrat pagament ultim mes',\n",
       " 'contamin agu',\n",
       " 'convers rob',\n",
       " 'quer consult cpf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\n",
    "  \"tokenizer\" : \"classic\",\n",
    "  \"filter\" : [\n",
    "              \"lowercase\",\n",
    "              \"asciifolding\",\n",
    "              {\"type\": \"stop\", \"stopwords\": \"_portuguese_\"},\n",
    "              {\"type\": \"stemmer\", \"language\": \"brazilian\"}],\n",
    "  \"text\" : \"\"\n",
    "}\n",
    "\n",
    "examples_text_without_stopwords = []\n",
    "for example in all_examples:\n",
    "    query[\"text\"] = example\n",
    "    result = es.indices.analyze(index=index.index_name, body=query)\n",
    "    new_text = \" \".join([token[\"token\"] for token in result[\"tokens\"]])\n",
    "    examples_text_without_stopwords.append(new_text)\n",
    "\n",
    "examples_text_without_stopwords[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Enconding the intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def intent_to_onehot(intents_names):\n",
    "    data = asarray([ [intent_name]  for intent_name in intents_names])\n",
    "    # define one hot encoding\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    # transform data\n",
    "    intents_names_as_onehot = encoder.fit_transform(data)\n",
    "    return intents_names_as_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_name = df_train.intent.tolist() + df_test.intent.tolist()\n",
    "set_intents_name = set(intents_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_intents_name = set(intents_name)\n",
    "intents_name_as_onehot = intent_to_onehot(set_intents_name)\n",
    "dic_onehot_intents = {intent: onehot for intent, onehot in zip(set_intents_name, intents_name_as_onehot)}\n",
    "dic_onehot_intents[\"Localizar_AgenciasCEDAE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('data/dic_onehot_intents_tfidf_cedae.npy',dic_onehot_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_dictionary = {str(np.argmax(value)):key for key, value in zip(dic_onehot_intents.keys(),\n",
    "                                            dic_onehot_intents.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/intents_dictionary_tfidf_cedae.json\", 'w') as f:\n",
    "      json.dump(intent_dictionary, f)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def encode_tfidf(all_examples):\n",
    "    # create the transform\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # tokenize and build vocab\n",
    "    tf_idf_corpus = vectorizer.fit(all_examples)\n",
    "    features = tf_idf_corpus.transform(all_examples)\n",
    "    return tf_idf_corpus, features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n",
      "previsa volt agu\n"
     ]
    }
   ],
   "source": [
    "train_examples_text_without_stopwords = examples_text_without_stopwords[:stard_idx_test]\n",
    "print(len(train_examples_text_without_stopwords))\n",
    "print(train_examples_text_without_stopwords[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "agu cor amarel\n"
     ]
    }
   ],
   "source": [
    "test_examples_text_without_stopwords = examples_text_without_stopwords[stard_idx_test:]\n",
    "print(len(test_examples_text_without_stopwords))\n",
    "print(test_examples_text_without_stopwords[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_test_idx = len(train_examples_text_without_stopwords)\n",
    "all_examples = train_examples_text_without_stopwords + test_examples_text_without_stopwords\n",
    "tf_idf_corpus, tf_idf = encode_tfidf(all_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 344)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#  save tf_idf_corpus instance\n",
    "pickle.dump(tf_idf_corpus, open(\"nlp_models/tf_idf_corpus_cedae.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.stack(tf_idf[:start_test_idx])\n",
    "y_train = np.stack([dic_onehot_intents[intent] for intent in df_train.intent])\n",
    "\n",
    "X_test = np.stack(tf_idf[start_test_idx:])\n",
    "y_test = np.stack([dic_onehot_intents[intent] for intent in df_test.intent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 221\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0], len(train_examples_text_without_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 106\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape[0], len(test_examples_text_without_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('data/X_train_tdidf_cedae.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "    f.close()\n",
    "    \n",
    "with open('data/y_train_tdidf_cedae.npy', 'wb') as f:\n",
    "    np.save(f, y_train)\n",
    "    f.close()\n",
    "    \n",
    "with open('data/X_test_tdidf_cedae.npy', 'wb') as f:\n",
    "    np.save(f, X_test)\n",
    "    f.close()\n",
    "    \n",
    "with open('data/y_test_tdidf_cedae.npy', 'wb') as f:\n",
    "    np.save(f, y_test)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
